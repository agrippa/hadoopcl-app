java: no process killed
java: no process killed
jmg3     26156  0.0  0.0 106084  1400 ?        Ss   14:17   0:00 bash -c ps aux | grep java
jmg3     26172  0.0  0.0 103232   844 ?        S    14:17   0:00 grep java
jmg3      9162  0.0  0.0 100928   620 pts/0    S+   13:34   0:00 tail -f kmeans.java.uncompressed.2
jmg3      9686  0.0  0.0  59072  3528 pts/0    S    14:17   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3      9692  0.0  0.0 106084  1400 ?        Ss   14:17   0:00 bash -c ps aux | grep java
jmg3      9708  0.0  0.0 103232   844 ?        S    14:17   0:00 grep java
java: no process killed
java: no process killed
jmg3     26218  0.0  0.0 106084  1396 ?        Ss   14:17   0:00 bash -c ps aux | grep java
jmg3     26234  0.0  0.0 103232   844 ?        S    14:17   0:00 grep java
jmg3      9162  0.0  0.0 100928   620 pts/0    S+   13:34   0:00 tail -f kmeans.java.uncompressed.2
jmg3      9769  0.0  0.0  59072  3528 pts/0    S    14:17   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3      9775  0.0  0.0 106084  1400 ?        Ss   14:17   0:00 bash -c ps aux | grep java
jmg3      9791  0.0  0.0 103232   844 ?        S    14:17   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 14:17:38 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 14:17:38 INFO util.GSet: VM type       = 64-bit
13/05/22 14:17:38 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 14:17:38 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 14:17:38 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 14:17:38 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 14:17:38 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 14:17:38 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 14:17:38 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 14:17:38 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 14:17:38 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 14:17:39 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 14:17:39 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 14:17:39 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 14:29:05 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 14:29:05 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 14:29:05 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 14:29:05 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 14:29:05 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 14:29:05 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 14:29:05 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 14:29:05 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 14:29:06 INFO mapred.JobClient: Running job: job_201305221417_0001
13/05/22 14:29:07 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 14:29:45 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 14:30:15 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 14:30:30 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 14:30:57 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 14:31:15 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 14:31:45 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 14:32:12 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 14:32:31 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 14:32:58 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 14:33:25 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 14:33:43 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 14:34:10 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 14:34:25 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 14:34:54 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 14:35:21 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 14:35:36 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 14:36:06 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 14:36:21 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 14:36:48 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 14:37:15 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 14:37:36 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 14:38:03 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 14:38:21 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 14:38:48 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 14:39:15 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 14:39:33 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 14:40:00 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 14:40:18 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 14:40:45 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 14:41:12 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 14:41:27 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 14:41:57 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 14:42:13 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 14:42:40 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 14:42:58 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 14:43:25 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 14:43:52 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 14:44:13 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 14:44:40 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 14:45:19 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 14:45:22 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 14:45:25 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 14:45:28 INFO mapred.JobClient:  map 40% reduce 4%
13/05/22 14:45:31 INFO mapred.JobClient:  map 40% reduce 5%
13/05/22 14:45:34 INFO mapred.JobClient:  map 40% reduce 7%
13/05/22 14:45:37 INFO mapred.JobClient:  map 40% reduce 8%
13/05/22 14:45:40 INFO mapred.JobClient:  map 40% reduce 10%
13/05/22 14:45:43 INFO mapred.JobClient:  map 40% reduce 12%
13/05/22 14:45:46 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 14:46:15 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 14:46:30 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 14:47:00 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 14:47:24 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 14:47:42 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 14:48:12 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 14:48:27 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 14:48:54 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 14:49:18 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 14:49:39 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 14:50:06 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 14:50:24 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 14:50:54 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 14:51:18 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 14:51:39 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 14:52:07 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 14:52:25 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 14:52:49 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 14:53:16 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 14:53:34 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 14:54:01 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 14:54:19 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 14:54:46 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 14:55:13 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 14:55:34 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 14:56:01 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 14:56:19 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 14:56:43 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 14:57:10 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 14:57:31 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 14:57:55 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 14:58:16 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 14:58:40 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 14:59:07 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 14:59:25 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 14:59:52 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 15:00:10 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 15:00:37 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 15:01:16 INFO mapred.JobClient:  map 80% reduce 14%
13/05/22 15:01:19 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 15:01:22 INFO mapred.JobClient:  map 80% reduce 18%
13/05/22 15:01:25 INFO mapred.JobClient:  map 80% reduce 21%
13/05/22 15:01:28 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 15:01:31 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 15:01:34 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 15:02:01 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 15:02:44 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 15:03:32 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 15:04:17 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 15:05:08 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 15:05:52 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 15:06:37 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 15:07:19 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 15:08:07 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 15:08:55 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 15:09:43 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 15:10:28 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 15:11:10 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 15:11:55 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 15:12:46 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 15:13:35 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 15:14:20 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 15:15:05 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 15:15:50 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 15:16:53 INFO mapred.JobClient:  map 100% reduce 28%
13/05/22 15:16:59 INFO mapred.JobClient:  map 100% reduce 30%
13/05/22 15:17:02 INFO mapred.JobClient:  map 100% reduce 32%
13/05/22 15:17:05 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 15:17:14 INFO mapred.JobClient:  map 100% reduce 52%
13/05/22 15:17:17 INFO mapred.JobClient:  map 100% reduce 77%
13/05/22 15:17:20 INFO mapred.JobClient:  map 100% reduce 87%
13/05/22 15:17:23 INFO mapred.JobClient:  map 100% reduce 92%
13/05/22 15:17:26 INFO mapred.JobClient:  map 100% reduce 98%
13/05/22 15:17:29 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 15:17:37 INFO mapred.JobClient: Job complete: job_201305221417_0001
13/05/22 15:17:37 INFO mapred.JobClient: Counters: 29
13/05/22 15:17:37 INFO mapred.JobClient:   Job Counters 
13/05/22 15:17:37 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 15:17:37 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28590988
13/05/22 15:17:37 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 15:17:37 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 15:17:37 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 15:17:37 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 15:17:37 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7729311
13/05/22 15:17:37 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 15:17:37 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 15:17:37 INFO mapred.JobClient:   FileSystemCounters
13/05/22 15:17:37 INFO mapred.JobClient:     FILE_BYTES_READ=5338559135
13/05/22 15:17:37 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 15:17:37 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612015554
13/05/22 15:17:37 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 15:17:37 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 15:17:37 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 15:17:37 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 15:17:37 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 15:17:37 INFO mapred.JobClient:     Map input records=120000000
13/05/22 15:17:37 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 15:17:37 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 15:17:37 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 15:17:37 INFO mapred.JobClient:     CPU time spent (ms)=28669290
13/05/22 15:17:37 INFO mapred.JobClient:     Total committed heap usage (bytes)=46857519104
13/05/22 15:17:37 INFO mapred.JobClient:     Combine input records=0
13/05/22 15:17:37 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 15:17:37 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 15:17:37 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 15:17:37 INFO mapred.JobClient:     Combine output records=0
13/05/22 15:17:37 INFO mapred.JobClient:     Physical memory (bytes) snapshot=40057102336
13/05/22 15:17:37 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 15:17:37 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658371952640
13/05/22 15:17:37 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2911820 ms

real	48m32.867s
user	0m6.343s
sys	0m1.024s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     29282  0.0  0.0 106084  1400 ?        Ss   15:17   0:00 bash -c ps aux | grep java
jmg3     29298  0.0  0.0 103232   844 ?        S    15:17   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     11267  0.0  0.0  59072  3528 pts/0    S    15:17   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     11273  0.0  0.0 106084  1400 ?        Ss   15:17   0:00 bash -c ps aux | grep java
jmg3     11289  0.0  0.0 103232   844 ?        S    15:17   0:00 grep java
java: no process killed
java: no process killed
jmg3     29344  0.0  0.0 106084  1396 ?        Ss   15:17   0:00 bash -c ps aux | grep java
jmg3     29360  0.0  0.0 103232   840 ?        S    15:17   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     11356  0.0  0.0  59072  3528 pts/0    S    15:17   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     11362  0.0  0.0 106084  1400 ?        Ss   15:17   0:00 bash -c ps aux | grep java
jmg3     11378  0.0  0.0 103232   844 ?        S    15:17   0:00 grep java
java: no process killed
java: no process killed
jmg3     29406  0.0  0.0 106084  1400 ?        Ss   15:17   0:00 bash -c ps aux | grep java
jmg3     29422  0.0  0.0 103232   844 ?        S    15:17   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     11439  0.0  0.0  59072  3532 pts/0    S    15:17   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     11445  0.0  0.0 106084  1400 ?        Ss   15:17   0:00 bash -c ps aux | grep java
jmg3     11461  0.0  0.0 103232   840 ?        S    15:17   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 15:17:50 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 15:17:50 INFO util.GSet: VM type       = 64-bit
13/05/22 15:17:50 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 15:17:50 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 15:17:50 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 15:17:50 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 15:17:51 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 15:17:51 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 15:17:51 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 15:17:51 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 15:17:51 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 15:17:51 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 15:17:51 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 15:17:51 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 15:23:28 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 15:23:28 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 15:23:28 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 15:23:28 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 15:23:28 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 15:23:28 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 15:23:28 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 15:23:28 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 15:23:29 INFO mapred.JobClient: Running job: job_201305221517_0001
13/05/22 15:23:30 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 15:24:08 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 15:24:38 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 15:24:53 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 15:25:23 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 15:25:38 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 15:26:05 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 15:26:35 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 15:26:53 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 15:27:20 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 15:27:47 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 15:28:05 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 15:28:32 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 15:28:50 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 15:29:18 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 15:29:45 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 15:30:03 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 15:30:30 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 15:30:45 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 15:31:15 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 15:31:42 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 15:31:57 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 15:32:27 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 15:32:45 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 15:33:12 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 15:33:39 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 15:33:57 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 15:34:24 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 15:34:42 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 15:35:09 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 15:35:36 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 15:35:54 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 15:36:21 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 15:36:36 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 15:37:03 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 15:37:21 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 15:37:48 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 15:38:18 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 15:38:36 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 15:39:04 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 15:39:43 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 15:39:52 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 15:39:55 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 15:39:58 INFO mapred.JobClient:  map 40% reduce 5%
13/05/22 15:40:01 INFO mapred.JobClient:  map 40% reduce 7%
13/05/22 15:40:04 INFO mapred.JobClient:  map 40% reduce 9%
13/05/22 15:40:07 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 15:40:10 INFO mapred.JobClient:  map 40% reduce 13%
13/05/22 15:40:13 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 15:40:40 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 15:40:55 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 15:41:25 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 15:41:48 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 15:42:09 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 15:42:36 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 15:42:54 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 15:43:21 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 15:43:42 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 15:44:06 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 15:44:33 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 15:44:51 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 15:45:18 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 15:45:42 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 15:46:03 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 15:46:30 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 15:46:48 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 15:47:15 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 15:47:39 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 15:48:00 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 15:48:27 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 15:48:45 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 15:49:13 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 15:49:37 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 15:50:01 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 15:50:25 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 15:50:43 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 15:51:10 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 15:51:34 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 15:51:55 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 15:52:22 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 15:52:40 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 15:53:07 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 15:53:31 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 15:53:52 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 15:54:19 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 15:54:37 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 15:55:04 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 15:55:40 INFO mapred.JobClient:  map 80% reduce 13%
13/05/22 15:55:43 INFO mapred.JobClient:  map 80% reduce 15%
13/05/22 15:55:46 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 15:55:49 INFO mapred.JobClient:  map 80% reduce 18%
13/05/22 15:55:52 INFO mapred.JobClient:  map 80% reduce 20%
13/05/22 15:55:55 INFO mapred.JobClient:  map 80% reduce 22%
13/05/22 15:55:58 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 15:56:01 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 15:56:04 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 15:56:25 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 15:57:10 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 15:57:55 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 15:58:40 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 15:59:31 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 16:00:17 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 16:01:05 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 16:01:47 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 16:02:32 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 16:03:23 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 16:04:08 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 16:04:56 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 16:05:38 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 16:06:23 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 16:07:14 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 16:07:59 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 16:08:44 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 16:09:29 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 16:10:14 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 16:11:18 INFO mapred.JobClient:  map 100% reduce 26%
13/05/22 16:11:21 INFO mapred.JobClient:  map 100% reduce 28%
13/05/22 16:11:24 INFO mapred.JobClient:  map 100% reduce 29%
13/05/22 16:11:27 INFO mapred.JobClient:  map 100% reduce 31%
13/05/22 16:11:30 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 16:11:36 INFO mapred.JobClient:  map 100% reduce 42%
13/05/22 16:11:39 INFO mapred.JobClient:  map 100% reduce 44%
13/05/22 16:11:42 INFO mapred.JobClient:  map 100% reduce 74%
13/05/22 16:11:45 INFO mapred.JobClient:  map 100% reduce 84%
13/05/22 16:11:48 INFO mapred.JobClient:  map 100% reduce 92%
13/05/22 16:11:54 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 16:11:59 INFO mapred.JobClient: Job complete: job_201305221517_0001
13/05/22 16:11:59 INFO mapred.JobClient: Counters: 29
13/05/22 16:11:59 INFO mapred.JobClient:   Job Counters 
13/05/22 16:11:59 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 16:11:59 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28620322
13/05/22 16:11:59 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 16:11:59 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 16:11:59 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 16:11:59 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 16:11:59 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7724729
13/05/22 16:11:59 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 16:11:59 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 16:11:59 INFO mapred.JobClient:   FileSystemCounters
13/05/22 16:11:59 INFO mapred.JobClient:     FILE_BYTES_READ=5338563430
13/05/22 16:11:59 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 16:11:59 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612019849
13/05/22 16:11:59 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 16:11:59 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 16:11:59 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 16:11:59 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 16:11:59 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 16:11:59 INFO mapred.JobClient:     Map input records=120000000
13/05/22 16:11:59 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 16:11:59 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 16:11:59 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 16:11:59 INFO mapred.JobClient:     CPU time spent (ms)=28696560
13/05/22 16:11:59 INFO mapred.JobClient:     Total committed heap usage (bytes)=43696128000
13/05/22 16:11:59 INFO mapred.JobClient:     Combine input records=0
13/05/22 16:11:59 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 16:11:59 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 16:11:59 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 16:11:59 INFO mapred.JobClient:     Combine output records=0
13/05/22 16:11:59 INFO mapred.JobClient:     Physical memory (bytes) snapshot=37006589952
13/05/22 16:11:59 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 16:11:59 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658304843776
13/05/22 16:11:59 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2910809 ms

real	48m31.864s
user	0m6.415s
sys	0m1.049s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     32463  0.0  0.0 106084  1400 ?        Ss   16:11   0:00 bash -c ps aux | grep java
jmg3     32479  0.0  0.0 103232   844 ?        S    16:11   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     12869  0.0  0.0  59072  3528 pts/0    S    16:11   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     12875  0.0  0.0 106084  1400 ?        Ss   16:11   0:00 bash -c ps aux | grep java
jmg3     12891  0.0  0.0 103232   844 ?        S    16:11   0:00 grep java
java: no process killed
java: no process killed
jmg3     32525  0.0  0.0 106084  1396 ?        Ss   16:12   0:00 bash -c ps aux | grep java
jmg3     32541  0.0  0.0 103232   844 ?        S    16:12   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     12957  0.0  0.0  59072  3528 pts/0    S    16:12   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     12963  0.0  0.0 106084  1400 ?        Ss   16:12   0:00 bash -c ps aux | grep java
jmg3     12979  0.0  0.0 103232   840 ?        S    16:12   0:00 grep java
java: no process killed
java: no process killed
jmg3     32587  0.0  0.0 106084  1400 ?        Ss   16:12   0:00 bash -c ps aux | grep java
jmg3     32603  0.0  0.0 103232   840 ?        S    16:12   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     13040  0.0  0.0  59072  3528 pts/0    S    16:12   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     13046  0.0  0.0 106084  1400 ?        Ss   16:12   0:00 bash -c ps aux | grep java
jmg3     13062  0.0  0.0 103232   844 ?        S    16:12   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 16:12:12 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 16:12:12 INFO util.GSet: VM type       = 64-bit
13/05/22 16:12:12 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 16:12:12 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 16:12:12 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 16:12:12 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 16:12:12 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 16:12:12 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 16:12:12 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 16:12:12 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 16:12:12 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 16:12:12 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 16:12:13 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 16:12:13 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 16:19:59 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 16:19:59 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 16:19:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 16:19:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 16:19:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 16:19:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 16:20:00 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 16:20:00 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 16:20:01 INFO mapred.JobClient: Running job: job_201305221612_0001
13/05/22 16:20:02 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 16:20:40 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 16:21:10 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 16:21:25 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 16:21:52 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 16:22:10 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 16:22:40 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 16:23:07 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 16:23:25 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 16:23:52 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 16:24:19 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 16:24:37 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 16:25:04 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 16:25:19 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 16:25:49 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 16:26:16 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 16:26:31 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 16:27:01 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 16:27:16 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 16:27:46 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 16:28:13 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 16:28:28 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 16:28:58 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 16:29:13 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 16:29:44 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 16:30:11 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 16:30:29 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 16:30:56 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 16:31:11 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 16:31:41 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 16:32:08 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 16:32:23 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 16:32:53 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 16:33:08 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 16:33:34 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 16:33:55 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 16:34:19 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 16:34:49 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 16:35:04 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 16:35:31 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 16:36:13 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 16:36:16 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 16:36:19 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 16:36:22 INFO mapred.JobClient:  map 40% reduce 4%
13/05/22 16:36:25 INFO mapred.JobClient:  map 40% reduce 6%
13/05/22 16:36:28 INFO mapred.JobClient:  map 40% reduce 8%
13/05/22 16:36:31 INFO mapred.JobClient:  map 40% reduce 10%
13/05/22 16:36:34 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 16:36:37 INFO mapred.JobClient:  map 40% reduce 13%
13/05/22 16:36:40 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 16:37:06 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 16:37:27 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 16:37:54 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 16:38:18 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 16:38:39 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 16:39:03 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 16:39:22 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 16:39:49 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 16:40:16 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 16:40:34 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 16:41:01 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 16:41:22 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 16:41:49 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 16:42:13 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 16:42:34 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 16:43:01 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 16:43:19 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 16:43:43 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 16:44:10 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 16:44:31 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 16:44:55 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 16:45:13 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 16:45:40 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 16:46:07 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 16:46:28 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 16:46:51 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 16:47:12 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 16:47:39 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 16:48:03 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 16:48:24 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 16:48:51 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 16:49:09 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 16:49:34 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 16:50:01 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 16:50:19 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 16:50:46 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 16:51:04 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 16:51:31 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 16:52:10 INFO mapred.JobClient:  map 80% reduce 15%
13/05/22 16:52:13 INFO mapred.JobClient:  map 80% reduce 17%
13/05/22 16:52:16 INFO mapred.JobClient:  map 80% reduce 20%
13/05/22 16:52:19 INFO mapred.JobClient:  map 80% reduce 21%
13/05/22 16:52:22 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 16:52:25 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 16:52:58 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 16:53:40 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 16:54:22 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 16:55:07 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 16:55:58 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 16:56:46 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 16:57:31 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 16:58:13 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 16:58:58 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 16:59:52 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 17:00:41 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 17:01:26 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 17:02:08 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 17:02:53 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 17:03:44 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 17:04:29 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 17:05:13 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 17:05:58 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 17:06:40 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 17:07:43 INFO mapred.JobClient:  map 100% reduce 26%
13/05/22 17:07:49 INFO mapred.JobClient:  map 100% reduce 29%
13/05/22 17:07:52 INFO mapred.JobClient:  map 100% reduce 31%
13/05/22 17:07:55 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 17:08:04 INFO mapred.JobClient:  map 100% reduce 41%
13/05/22 17:08:07 INFO mapred.JobClient:  map 100% reduce 54%
13/05/22 17:08:10 INFO mapred.JobClient:  map 100% reduce 76%
13/05/22 17:08:13 INFO mapred.JobClient:  map 100% reduce 84%
13/05/22 17:08:16 INFO mapred.JobClient:  map 100% reduce 87%
13/05/22 17:08:19 INFO mapred.JobClient:  map 100% reduce 89%
13/05/22 17:08:22 INFO mapred.JobClient:  map 100% reduce 95%
13/05/22 17:08:25 INFO mapred.JobClient:  map 100% reduce 98%
13/05/22 17:08:28 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 17:08:33 INFO mapred.JobClient: Job complete: job_201305221612_0001
13/05/22 17:08:33 INFO mapred.JobClient: Counters: 29
13/05/22 17:08:33 INFO mapred.JobClient:   Job Counters 
13/05/22 17:08:33 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 17:08:33 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28596009
13/05/22 17:08:33 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 17:08:33 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 17:08:33 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 17:08:33 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 17:08:33 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7731858
13/05/22 17:08:33 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 17:08:33 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 17:08:33 INFO mapred.JobClient:   FileSystemCounters
13/05/22 17:08:33 INFO mapred.JobClient:     FILE_BYTES_READ=5338560046
13/05/22 17:08:33 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 17:08:33 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612016465
13/05/22 17:08:33 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 17:08:33 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 17:08:33 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 17:08:33 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 17:08:33 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 17:08:33 INFO mapred.JobClient:     Map input records=120000000
13/05/22 17:08:33 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 17:08:33 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 17:08:33 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 17:08:33 INFO mapred.JobClient:     CPU time spent (ms)=28696770
13/05/22 17:08:33 INFO mapred.JobClient:     Total committed heap usage (bytes)=45711294464
13/05/22 17:08:33 INFO mapred.JobClient:     Combine input records=0
13/05/22 17:08:33 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 17:08:33 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 17:08:33 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 17:08:33 INFO mapred.JobClient:     Combine output records=0
13/05/22 17:08:33 INFO mapred.JobClient:     Physical memory (bytes) snapshot=39305986048
13/05/22 17:08:33 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 17:08:33 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658303791104
13/05/22 17:08:33 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2913845 ms

real	48m34.905s
user	0m6.337s
sys	0m1.088s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3      3286  0.0  0.0 106084  1404 ?        Ss   17:08   0:00 bash -c ps aux | grep java
jmg3      3302  0.0  0.0 103232   844 ?        S    17:08   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     14482  0.0  0.0  59072  3528 pts/0    S    17:08   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     14488  0.0  0.0 106084  1404 ?        Ss   17:08   0:00 bash -c ps aux | grep java
jmg3     14504  0.0  0.0 103232   844 ?        S    17:08   0:00 grep java
java: no process killed
java: no process killed
jmg3      3348  0.0  0.0 106084  1396 ?        Ss   17:08   0:00 bash -c ps aux | grep java
jmg3      3364  0.0  0.0 103232   844 ?        S    17:08   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     14570  0.0  0.0  59072  3528 pts/0    S    17:08   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     14576  0.0  0.0 106084  1396 ?        Ss   17:08   0:00 bash -c ps aux | grep java
jmg3     14592  0.0  0.0 103232   840 ?        S    17:08   0:00 grep java
java: no process killed
java: no process killed
jmg3      3411  0.0  0.0 106084  1400 ?        Ss   17:08   0:00 bash -c ps aux | grep java
jmg3      3427  0.0  0.0 103232   840 ?        S    17:08   0:00 grep java
jmg3     10681  0.0  0.0 100928   620 pts/0    S+   14:19   0:00 tail -f kmeans.java.compressed
jmg3     14653  0.0  0.0  59072  3528 pts/0    S    17:08   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     14659  0.0  0.0 106084  1396 ?        Ss   17:08   0:00 bash -c ps aux | grep java
jmg3     14675  0.0  0.0 103232   840 ?        S    17:08   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 17:08:48 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 17:08:48 INFO util.GSet: VM type       = 64-bit
13/05/22 17:08:48 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 17:08:48 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 17:08:48 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 17:08:48 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 17:08:48 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 17:08:48 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 17:08:48 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 17:08:48 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 17:08:48 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 17:08:48 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 17:08:48 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 17:08:48 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 17:15:42 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 17:15:42 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 17:15:42 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 17:15:42 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 17:15:42 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 17:15:42 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 17:15:42 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 17:15:42 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 17:15:43 INFO mapred.JobClient: Running job: job_201305221708_0001
13/05/22 17:15:44 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 17:16:24 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 17:16:54 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 17:17:09 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 17:17:39 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 17:17:54 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 17:18:24 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 17:18:51 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 17:19:09 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 17:19:36 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 17:20:06 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 17:20:22 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 17:20:49 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 17:21:07 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 17:21:34 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 17:22:01 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 17:22:19 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 17:22:46 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 17:23:01 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 17:23:30 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 17:23:57 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 17:24:12 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 17:24:42 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 17:24:57 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 17:25:27 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 17:25:54 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 17:26:12 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 17:26:39 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 17:26:57 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 17:27:24 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 17:27:51 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 17:28:06 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 17:28:36 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 17:28:51 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 17:29:18 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 17:29:36 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 17:30:04 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 17:30:34 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 17:30:49 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 17:31:19 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 17:31:58 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 17:32:04 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 17:32:07 INFO mapred.JobClient:  map 40% reduce 2%
13/05/22 17:32:10 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 17:32:13 INFO mapred.JobClient:  map 40% reduce 5%
13/05/22 17:32:16 INFO mapred.JobClient:  map 40% reduce 7%
13/05/22 17:32:19 INFO mapred.JobClient:  map 40% reduce 9%
13/05/22 17:32:22 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 17:32:25 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 17:32:54 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 17:33:12 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 17:33:39 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 17:34:03 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 17:34:24 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 17:34:51 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 17:35:08 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 17:35:35 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 17:36:02 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 17:36:23 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 17:36:50 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 17:37:05 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 17:37:32 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 17:37:56 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 17:38:17 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 17:38:44 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 17:39:02 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 17:39:29 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 17:39:54 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 17:40:15 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 17:40:42 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 17:41:00 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 17:41:27 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 17:41:51 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 17:42:12 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 17:42:42 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 17:43:00 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 17:43:24 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 17:43:48 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 17:44:09 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 17:44:36 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 17:44:54 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 17:45:21 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 17:45:45 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 17:46:06 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 17:46:33 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 17:46:51 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 17:47:18 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 17:47:57 INFO mapred.JobClient:  map 80% reduce 14%
13/05/22 17:48:00 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 17:48:03 INFO mapred.JobClient:  map 80% reduce 19%
13/05/22 17:48:06 INFO mapred.JobClient:  map 80% reduce 21%
13/05/22 17:48:09 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 17:48:12 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 17:48:15 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 17:48:39 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 17:49:27 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 17:50:13 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 17:50:58 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 17:51:52 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 17:52:34 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 17:53:19 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 17:54:04 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 17:54:49 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 17:55:40 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 17:56:25 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 17:57:10 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 17:57:55 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 17:58:40 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 17:59:31 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 18:00:16 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 18:01:05 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 18:01:50 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 18:02:32 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 18:03:34 INFO mapred.JobClient:  map 100% reduce 26%
13/05/22 18:03:37 INFO mapred.JobClient:  map 100% reduce 29%
13/05/22 18:03:40 INFO mapred.JobClient:  map 100% reduce 30%
13/05/22 18:03:43 INFO mapred.JobClient:  map 100% reduce 31%
13/05/22 18:03:46 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 18:03:52 INFO mapred.JobClient:  map 100% reduce 41%
13/05/22 18:03:55 INFO mapred.JobClient:  map 100% reduce 54%
13/05/22 18:03:58 INFO mapred.JobClient:  map 100% reduce 78%
13/05/22 18:04:01 INFO mapred.JobClient:  map 100% reduce 86%
13/05/22 18:04:04 INFO mapred.JobClient:  map 100% reduce 94%
13/05/22 18:04:10 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 18:04:15 INFO mapred.JobClient: Job complete: job_201305221708_0001
13/05/22 18:04:15 INFO mapred.JobClient: Counters: 29
13/05/22 18:04:15 INFO mapred.JobClient:   Job Counters 
13/05/22 18:04:15 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 18:04:15 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28616180
13/05/22 18:04:15 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 18:04:15 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 18:04:15 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 18:04:15 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 18:04:15 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7728717
13/05/22 18:04:15 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 18:04:15 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 18:04:15 INFO mapred.JobClient:   FileSystemCounters
13/05/22 18:04:15 INFO mapred.JobClient:     FILE_BYTES_READ=5338560180
13/05/22 18:04:15 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 18:04:15 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612016599
13/05/22 18:04:15 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 18:04:15 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 18:04:15 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 18:04:15 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 18:04:15 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 18:04:15 INFO mapred.JobClient:     Map input records=120000000
13/05/22 18:04:15 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 18:04:15 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 18:04:15 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 18:04:15 INFO mapred.JobClient:     CPU time spent (ms)=28676620
13/05/22 18:04:15 INFO mapred.JobClient:     Total committed heap usage (bytes)=40826175488
13/05/22 18:04:15 INFO mapred.JobClient:     Combine input records=0
13/05/22 18:04:15 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 18:04:15 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 18:04:15 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 18:04:15 INFO mapred.JobClient:     Combine output records=0
13/05/22 18:04:15 INFO mapred.JobClient:     Physical memory (bytes) snapshot=34034487296
13/05/22 18:04:15 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 18:04:15 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658371952640
13/05/22 18:04:15 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2912964 ms

real	48m34.010s
user	0m6.271s
sys	0m1.117s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3      6570  0.0  0.0 106084  1400 ?        Ss   18:04   0:00 bash -c ps aux | grep java
jmg3      6586  0.0  0.0 103232   840 ?        S    18:04   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     16110  0.0  0.0  59072  3532 pts/0    S    18:04   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     16116  0.0  0.0 106084  1400 ?        Ss   18:04   0:00 bash -c ps aux | grep java
jmg3     16132  0.0  0.0 103232   840 ?        R    18:04   0:00 grep java
java: no process killed
java: no process killed
jmg3      6632  0.0  0.0 106084  1400 ?        Ss   18:04   0:00 bash -c ps aux | grep java
jmg3      6648  0.0  0.0 103232   844 ?        S    18:04   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     16198  0.0  0.0  59072  3532 pts/0    S    18:04   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     16204  0.0  0.0 106084  1400 ?        Ss   18:04   0:00 bash -c ps aux | grep java
jmg3     16220  0.0  0.0 103232   840 ?        R    18:04   0:00 grep java
java: no process killed
java: no process killed
jmg3      6694  0.0  0.0 106084  1400 ?        Ss   18:04   0:00 bash -c ps aux | grep java
jmg3      6710  0.0  0.0 103232   840 ?        S    18:04   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     16281  0.0  0.0  59072  3528 pts/0    S    18:04   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     16287  0.0  0.0 106084  1400 ?        Ss   18:04   0:00 bash -c ps aux | grep java
jmg3     16303  0.0  0.0 103232   844 ?        R    18:04   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 18:04:30 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 18:04:30 INFO util.GSet: VM type       = 64-bit
13/05/22 18:04:30 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 18:04:30 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 18:04:30 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 18:04:30 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 18:04:30 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 18:04:30 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 18:04:30 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 18:04:30 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 18:04:30 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 18:04:31 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 18:04:31 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 18:04:31 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 18:13:27 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 18:13:27 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 18:13:27 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 18:13:27 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 18:13:27 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 18:13:27 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 18:13:27 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 18:13:28 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 18:13:28 INFO mapred.JobClient: Running job: job_201305221804_0001
13/05/22 18:13:29 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 18:14:06 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 18:14:36 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 18:14:52 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 18:15:22 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 18:15:37 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 18:16:07 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 18:16:34 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 18:16:52 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 18:17:19 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 18:17:46 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 18:18:04 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 18:18:31 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 18:18:46 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 18:19:16 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 18:19:43 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 18:19:58 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 18:20:28 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 18:20:43 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 18:21:13 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 18:21:40 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 18:21:55 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 18:22:25 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 18:22:43 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 18:23:10 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 18:23:37 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 18:23:55 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 18:24:22 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 18:24:41 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 18:25:08 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 18:25:35 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 18:25:53 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 18:26:20 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 18:26:35 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 18:27:04 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 18:27:22 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 18:27:46 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 18:28:16 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 18:28:34 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 18:29:01 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 18:29:40 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 18:29:43 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 18:29:46 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 18:29:49 INFO mapred.JobClient:  map 40% reduce 5%
13/05/22 18:29:52 INFO mapred.JobClient:  map 40% reduce 6%
13/05/22 18:29:55 INFO mapred.JobClient:  map 40% reduce 8%
13/05/22 18:29:58 INFO mapred.JobClient:  map 40% reduce 10%
13/05/22 18:30:01 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 18:30:04 INFO mapred.JobClient:  map 40% reduce 13%
13/05/22 18:30:07 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 18:30:37 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 18:30:55 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 18:31:22 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 18:31:43 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 18:32:07 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 18:32:31 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 18:32:49 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 18:33:16 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 18:33:40 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 18:34:01 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 18:34:29 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 18:34:50 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 18:35:14 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 18:35:38 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 18:36:02 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 18:36:29 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 18:36:47 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 18:37:14 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 18:37:35 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 18:37:56 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 18:38:23 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 18:38:41 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 18:39:08 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 18:39:35 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 18:39:53 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 18:40:20 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 18:40:38 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 18:41:05 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 18:41:32 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 18:41:52 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 18:42:16 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 18:42:37 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 18:43:01 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 18:43:28 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 18:43:49 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 18:44:14 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 18:44:32 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 18:44:59 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 18:45:38 INFO mapred.JobClient:  map 80% reduce 14%
13/05/22 18:45:41 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 18:45:44 INFO mapred.JobClient:  map 80% reduce 19%
13/05/22 18:45:47 INFO mapred.JobClient:  map 80% reduce 21%
13/05/22 18:45:50 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 18:45:53 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 18:45:56 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 18:46:24 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 18:47:06 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 18:47:50 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 18:48:35 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 18:49:29 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 18:50:17 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 18:50:59 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 18:51:44 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 18:52:26 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 18:53:20 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 18:54:05 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 18:54:51 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 18:55:33 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 18:56:18 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 18:57:12 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 18:57:57 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 18:58:42 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 18:59:24 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 19:00:12 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 19:01:15 INFO mapred.JobClient:  map 100% reduce 27%
13/05/22 19:01:21 INFO mapred.JobClient:  map 100% reduce 31%
13/05/22 19:01:24 INFO mapred.JobClient:  map 100% reduce 32%
13/05/22 19:01:27 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 19:01:36 INFO mapred.JobClient:  map 100% reduce 42%
13/05/22 19:01:39 INFO mapred.JobClient:  map 100% reduce 75%
13/05/22 19:01:42 INFO mapred.JobClient:  map 100% reduce 85%
13/05/22 19:01:45 INFO mapred.JobClient:  map 100% reduce 92%
13/05/22 19:01:51 INFO mapred.JobClient:  map 100% reduce 96%
13/05/22 19:01:54 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 19:01:59 INFO mapred.JobClient: Job complete: job_201305221804_0001
13/05/22 19:01:59 INFO mapred.JobClient: Counters: 29
13/05/22 19:01:59 INFO mapred.JobClient:   Job Counters 
13/05/22 19:01:59 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 19:01:59 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28602748
13/05/22 19:01:59 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 19:01:59 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 19:01:59 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 19:01:59 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 19:01:59 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7737789
13/05/22 19:01:59 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 19:01:59 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 19:01:59 INFO mapred.JobClient:   FileSystemCounters
13/05/22 19:01:59 INFO mapred.JobClient:     FILE_BYTES_READ=5338564024
13/05/22 19:01:59 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 19:01:59 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612020443
13/05/22 19:01:59 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 19:01:59 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 19:01:59 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 19:01:59 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 19:01:59 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 19:01:59 INFO mapred.JobClient:     Map input records=120000000
13/05/22 19:01:59 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 19:01:59 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 19:01:59 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 19:01:59 INFO mapred.JobClient:     CPU time spent (ms)=28698510
13/05/22 19:01:59 INFO mapred.JobClient:     Total committed heap usage (bytes)=45587103744
13/05/22 19:01:59 INFO mapred.JobClient:     Combine input records=0
13/05/22 19:01:59 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 19:01:59 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 19:01:59 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 19:01:59 INFO mapred.JobClient:     Combine output records=0
13/05/22 19:01:59 INFO mapred.JobClient:     Physical memory (bytes) snapshot=36097908736
13/05/22 19:01:59 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 19:01:59 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658575384576
13/05/22 19:01:59 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2911981 ms

real	48m33.026s
user	0m6.518s
sys	0m1.021s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3      9747  0.0  0.0 106084  1400 ?        Ss   19:02   0:00 bash -c ps aux | grep java
jmg3      9763  0.0  0.0 103232   840 ?        S    19:02   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     17737  0.0  0.0  59072  3528 pts/0    S    19:02   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     17743  0.0  0.0 106084  1400 ?        Ss   19:02   0:00 bash -c ps aux | grep java
jmg3     17759  0.0  0.0 103232   840 ?        R    19:02   0:00 grep java
java: no process killed
java: no process killed
jmg3      9809  0.0  0.0 106084  1400 ?        Ss   19:02   0:00 bash -c ps aux | grep java
jmg3      9825  0.0  0.0 103232   840 ?        S    19:02   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     17825  0.0  0.0  59072  3532 pts/0    S    19:02   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     17831  0.0  0.0 106084  1396 ?        Ss   19:02   0:00 bash -c ps aux | grep java
jmg3     17847  0.0  0.0 103232   840 ?        R    19:02   0:00 grep java
java: no process killed
java: no process killed
jmg3      9871  0.0  0.0 106084  1396 ?        Ss   19:02   0:00 bash -c ps aux | grep java
jmg3      9887  0.0  0.0 103232   844 ?        S    19:02   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     17908  0.0  0.0  59072  3532 pts/0    S    19:02   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     17914  0.0  0.0 106084  1400 ?        Ss   19:02   0:00 bash -c ps aux | grep java
jmg3     17930  0.0  0.0 103232   840 ?        R    19:02   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 19:02:14 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 19:02:14 INFO util.GSet: VM type       = 64-bit
13/05/22 19:02:14 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 19:02:14 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 19:02:14 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 19:02:15 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 19:02:15 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 19:02:15 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 19:02:15 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 19:02:15 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 19:02:15 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 19:02:15 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 19:02:15 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 19:02:15 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 19:10:59 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 19:10:59 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 19:10:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 19:10:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 19:10:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 19:10:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 19:10:59 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 19:11:00 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 19:11:00 INFO mapred.JobClient: Running job: job_201305221902_0001
13/05/22 19:11:01 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 19:11:40 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 19:12:11 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 19:12:26 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 19:12:56 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 19:13:11 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 19:13:38 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 19:14:08 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 19:14:26 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 19:14:53 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 19:15:23 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 19:15:38 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 19:16:05 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 19:16:20 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 19:16:50 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 19:17:17 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 19:17:32 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 19:18:02 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 19:18:17 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 19:18:46 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 19:19:13 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 19:19:28 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 19:19:58 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 19:20:16 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 19:20:43 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 19:21:10 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 19:21:28 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 19:21:56 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 19:22:14 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 19:22:41 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 19:23:08 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 19:23:26 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 19:23:53 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 19:24:08 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 19:24:35 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 19:24:53 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 19:25:20 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 19:25:50 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 19:26:05 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 19:26:35 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 19:27:17 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 19:27:23 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 19:27:26 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 19:27:29 INFO mapred.JobClient:  map 40% reduce 6%
13/05/22 19:27:32 INFO mapred.JobClient:  map 40% reduce 8%
13/05/22 19:27:35 INFO mapred.JobClient:  map 40% reduce 10%
13/05/22 19:27:38 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 19:27:41 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 19:28:09 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 19:28:27 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 19:28:57 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 19:29:21 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 19:29:42 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 19:30:09 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 19:30:27 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 19:30:54 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 19:31:18 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 19:31:36 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 19:32:07 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 19:32:25 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 19:32:49 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 19:33:16 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 19:33:37 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 19:34:04 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 19:34:22 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 19:34:49 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 19:35:16 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 19:35:34 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 19:36:01 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 19:36:19 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 19:36:46 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 19:37:10 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 19:37:28 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 19:37:58 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 19:38:16 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 19:38:40 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 19:39:07 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 19:39:27 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 19:39:54 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 19:40:12 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 19:40:39 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 19:41:03 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 19:41:24 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 19:41:51 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 19:42:06 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 19:42:34 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 19:43:13 INFO mapred.JobClient:  map 80% reduce 13%
13/05/22 19:43:16 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 19:43:18 INFO mapred.JobClient: Task Id : attempt_201305221902_0001_m_000025_0, Status : FAILED
Throwable.toString: java.io.IOException: Task process exit with nonzero status of 126.
Throwable.getMessage: Task process exit with nonzero status of 126.
baos: java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:274)
Caused by: java.io.IOException: Task process exit with nonzero status of 126.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:261)

13/05/22 19:43:18 WARN mapred.JobClient: Error reading task outputhttp://gpu-008.davinci.rice.edu:50060/tasklog?plaintext=true&attemptid=attempt_201305221902_0001_m_000025_0&filter=stdout
13/05/22 19:43:18 WARN mapred.JobClient: Error reading task outputhttp://gpu-008.davinci.rice.edu:50060/tasklog?plaintext=true&attemptid=attempt_201305221902_0001_m_000025_0&filter=stderr
13/05/22 19:43:19 INFO mapred.JobClient:  map 80% reduce 18%
13/05/22 19:43:22 INFO mapred.JobClient:  map 80% reduce 21%
13/05/22 19:43:25 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 19:43:28 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 19:43:31 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 19:44:00 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 19:44:42 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 19:45:24 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 19:46:12 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 19:47:03 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 19:47:48 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 19:48:33 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 19:49:15 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 19:50:00 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 19:50:54 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 19:51:40 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 19:52:25 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 19:53:10 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 19:53:54 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 19:54:48 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 19:55:33 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 19:56:15 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 19:57:00 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 19:57:45 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 19:58:51 INFO mapred.JobClient:  map 99% reduce 27%
13/05/22 19:58:54 INFO mapred.JobClient:  map 100% reduce 30%
13/05/22 19:58:57 INFO mapred.JobClient:  map 100% reduce 32%
13/05/22 19:59:03 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 19:59:12 INFO mapred.JobClient:  map 100% reduce 61%
13/05/22 19:59:15 INFO mapred.JobClient:  map 100% reduce 78%
13/05/22 19:59:18 INFO mapred.JobClient:  map 100% reduce 88%
13/05/22 19:59:21 INFO mapred.JobClient:  map 100% reduce 93%
13/05/22 19:59:24 INFO mapred.JobClient:  map 100% reduce 99%
13/05/22 19:59:27 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 19:59:32 INFO mapred.JobClient: Job complete: job_201305221902_0001
13/05/22 19:59:32 INFO mapred.JobClient: Counters: 29
13/05/22 19:59:32 INFO mapred.JobClient:   Job Counters 
13/05/22 19:59:32 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 19:59:32 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28617671
13/05/22 19:59:32 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 19:59:32 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 19:59:32 INFO mapred.JobClient:     Launched map tasks=31
13/05/22 19:59:32 INFO mapred.JobClient:     Data-local map tasks=31
13/05/22 19:59:32 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7729400
13/05/22 19:59:32 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 19:59:32 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 19:59:32 INFO mapred.JobClient:   FileSystemCounters
13/05/22 19:59:32 INFO mapred.JobClient:     FILE_BYTES_READ=5338556169
13/05/22 19:59:32 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 19:59:32 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612012588
13/05/22 19:59:32 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 19:59:32 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 19:59:32 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 19:59:32 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 19:59:32 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 19:59:32 INFO mapred.JobClient:     Map input records=120000000
13/05/22 19:59:32 INFO mapred.JobClient:     Reduce shuffle bytes=2083316271
13/05/22 19:59:32 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 19:59:32 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 19:59:32 INFO mapred.JobClient:     CPU time spent (ms)=28687610
13/05/22 19:59:32 INFO mapred.JobClient:     Total committed heap usage (bytes)=47692316672
13/05/22 19:59:32 INFO mapred.JobClient:     Combine input records=0
13/05/22 19:59:32 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 19:59:32 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 19:59:32 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 19:59:32 INFO mapred.JobClient:     Combine output records=0
13/05/22 19:59:32 INFO mapred.JobClient:     Physical memory (bytes) snapshot=37983539200
13/05/22 19:59:32 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 19:59:32 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658440114176
13/05/22 19:59:32 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2912919 ms

real	48m33.961s
user	0m6.340s
sys	0m1.012s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     13000  0.0  0.0 106084  1396 ?        Ss   19:59   0:00 bash -c ps aux | grep java
jmg3     13016  0.0  0.0 103232   840 ?        S    19:59   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     19354  0.0  0.0  59072  3532 pts/0    S    19:59   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     19360  0.0  0.0 106084  1400 ?        Ss   19:59   0:00 bash -c ps aux | grep java
jmg3     19376  0.0  0.0 103232   840 ?        R    19:59   0:00 grep java
java: no process killed
java: no process killed
jmg3     13062  0.0  0.0 106084  1400 ?        Ss   19:59   0:00 bash -c ps aux | grep java
jmg3     13078  0.0  0.0 103232   840 ?        S    19:59   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     19442  0.0  0.0  59072  3532 pts/0    S    19:59   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     19448  0.0  0.0 106084  1400 ?        Ss   19:59   0:00 bash -c ps aux | grep java
jmg3     19464  0.0  0.0 103232   844 ?        R    19:59   0:00 grep java
java: no process killed
java: no process killed
jmg3     13124  0.0  0.0 106084  1400 ?        Ss   19:59   0:00 bash -c ps aux | grep java
jmg3     13140  0.0  0.0 103232   840 ?        S    19:59   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     19525  0.0  0.0  59072  3532 pts/0    S    19:59   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     19531  0.0  0.0 106084  1396 ?        Ss   19:59   0:00 bash -c ps aux | grep java
jmg3     19547  0.0  0.0 103232   848 ?        R    19:59   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 19:59:47 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 19:59:47 INFO util.GSet: VM type       = 64-bit
13/05/22 19:59:47 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 19:59:47 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 19:59:47 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 19:59:47 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 19:59:47 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 19:59:47 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 19:59:47 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 19:59:47 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 19:59:47 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 19:59:47 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 19:59:47 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 19:59:47 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 20:09:52 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 20:09:52 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 20:09:53 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 20:09:53 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 20:09:53 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 20:09:53 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 20:09:53 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 20:09:53 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 20:09:54 INFO mapred.JobClient: Running job: job_201305221959_0001
13/05/22 20:09:55 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 20:10:33 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 20:11:03 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 20:11:18 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 20:11:48 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 20:12:03 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 20:12:30 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 20:13:00 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 20:13:18 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 20:13:45 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 20:14:15 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 20:14:30 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 20:14:57 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 20:15:12 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 20:15:42 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 20:16:09 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 20:16:24 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 20:16:55 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 20:17:10 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 20:17:40 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 20:18:07 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 20:18:22 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 20:18:52 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 20:19:10 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 20:19:37 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 20:20:01 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 20:20:22 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 20:20:49 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 20:21:07 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 20:21:34 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 20:22:01 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 20:22:16 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 20:22:46 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 20:23:01 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 20:23:27 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 20:23:48 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 20:24:12 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 20:24:42 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 20:24:57 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 20:25:27 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 20:26:06 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 20:26:09 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 20:26:12 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 20:26:16 INFO mapred.JobClient:  map 40% reduce 4%
13/05/22 20:26:19 INFO mapred.JobClient:  map 40% reduce 6%
13/05/22 20:26:22 INFO mapred.JobClient:  map 40% reduce 8%
13/05/22 20:26:25 INFO mapred.JobClient:  map 40% reduce 10%
13/05/22 20:26:28 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 20:26:31 INFO mapred.JobClient:  map 40% reduce 13%
13/05/22 20:26:34 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 20:27:01 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 20:27:19 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 20:27:46 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 20:28:10 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 20:28:31 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 20:28:58 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 20:29:16 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 20:29:46 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 20:30:10 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 20:30:31 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 20:30:58 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 20:31:16 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 20:31:43 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 20:32:04 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 20:32:25 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 20:32:55 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 20:33:10 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 20:33:37 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 20:34:01 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 20:34:22 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 20:34:52 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 20:35:07 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 20:35:37 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 20:36:01 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 20:36:23 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 20:36:50 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 20:37:08 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 20:37:32 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 20:37:56 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 20:38:20 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 20:38:43 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 20:39:01 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 20:39:28 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 20:39:52 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 20:40:13 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 20:40:43 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 20:40:58 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 20:41:25 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 20:42:07 INFO mapred.JobClient:  map 80% reduce 14%
13/05/22 20:42:10 INFO mapred.JobClient:  map 80% reduce 17%
13/05/22 20:42:13 INFO mapred.JobClient:  map 80% reduce 19%
13/05/22 20:42:16 INFO mapred.JobClient:  map 80% reduce 21%
13/05/22 20:42:19 INFO mapred.JobClient:  map 80% reduce 23%
13/05/22 20:42:22 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 20:42:27 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 20:42:48 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 20:43:33 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 20:44:18 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 20:45:06 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 20:45:57 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 20:46:41 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 20:47:24 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 20:48:09 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 20:48:54 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 20:49:48 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 20:50:33 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 20:51:15 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 20:52:00 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 20:52:45 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 20:53:36 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 20:54:24 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 20:55:09 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 20:55:54 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 20:56:39 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 20:57:43 INFO mapred.JobClient:  map 100% reduce 27%
13/05/22 20:57:46 INFO mapred.JobClient:  map 100% reduce 29%
13/05/22 20:57:49 INFO mapred.JobClient:  map 100% reduce 31%
13/05/22 20:57:52 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 20:58:04 INFO mapred.JobClient:  map 100% reduce 71%
13/05/22 20:58:07 INFO mapred.JobClient:  map 100% reduce 81%
13/05/22 20:58:10 INFO mapred.JobClient:  map 100% reduce 86%
13/05/22 20:58:13 INFO mapred.JobClient:  map 100% reduce 95%
13/05/22 20:58:19 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 20:58:24 INFO mapred.JobClient: Job complete: job_201305221959_0001
13/05/22 20:58:24 INFO mapred.JobClient: Counters: 29
13/05/22 20:58:24 INFO mapred.JobClient:   Job Counters 
13/05/22 20:58:24 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 20:58:24 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28593261
13/05/22 20:58:24 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 20:58:24 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 20:58:24 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 20:58:24 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 20:58:24 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7739375
13/05/22 20:58:24 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 20:58:24 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 20:58:24 INFO mapred.JobClient:   FileSystemCounters
13/05/22 20:58:24 INFO mapred.JobClient:     FILE_BYTES_READ=5338559402
13/05/22 20:58:24 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 20:58:24 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612015821
13/05/22 20:58:24 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 20:58:24 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 20:58:24 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 20:58:24 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 20:58:24 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 20:58:24 INFO mapred.JobClient:     Map input records=120000000
13/05/22 20:58:24 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 20:58:24 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 20:58:24 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 20:58:24 INFO mapred.JobClient:     CPU time spent (ms)=28690700
13/05/22 20:58:24 INFO mapred.JobClient:     Total committed heap usage (bytes)=47871623168
13/05/22 20:58:24 INFO mapred.JobClient:     Combine input records=0
13/05/22 20:58:24 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 20:58:24 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 20:58:24 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 20:58:24 INFO mapred.JobClient:     Combine output records=0
13/05/22 20:58:24 INFO mapred.JobClient:     Physical memory (bytes) snapshot=41140396032
13/05/22 20:58:24 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 20:58:24 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658303791104
13/05/22 20:58:24 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2910841 ms

real	48m31.896s
user	0m6.384s
sys	0m1.048s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     16206  0.0  0.0 106084  1400 ?        Ss   20:58   0:00 bash -c ps aux | grep java
jmg3     16222  0.0  0.0 103232   840 ?        S    20:58   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     20992  0.0  0.0  59072  3528 pts/0    S    20:58   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     20998  0.0  0.0 106084  1400 ?        Ss   20:58   0:00 bash -c ps aux | grep java
jmg3     21014  0.0  0.0 103232   844 ?        R    20:58   0:00 grep java
java: no process killed
java: no process killed
jmg3     16268  0.0  0.0 106084  1396 ?        Ss   20:58   0:00 bash -c ps aux | grep java
jmg3     16284  0.0  0.0 103232   840 ?        S    20:58   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     21081  0.0  0.0  59072  3532 pts/0    S    20:58   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     21087  0.0  0.0 106084  1396 ?        Ss   20:58   0:00 bash -c ps aux | grep java
jmg3     21103  0.0  0.0 103232   840 ?        R    20:58   0:00 grep java
java: no process killed
java: no process killed
jmg3     16331  0.0  0.0 106084  1396 ?        Ss   20:58   0:00 bash -c ps aux | grep java
jmg3     16347  0.0  0.0 103232   840 ?        S    20:58   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     21164  0.0  0.0  59072  3524 pts/0    S    20:58   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     21170  0.0  0.0 106084  1400 ?        Ss   20:58   0:00 bash -c ps aux | grep java
jmg3     21186  0.0  0.0 103232   840 ?        R    20:58   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 20:58:39 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 20:58:39 INFO util.GSet: VM type       = 64-bit
13/05/22 20:58:39 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 20:58:39 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 20:58:39 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 20:58:39 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 20:58:39 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 20:58:39 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 20:58:39 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 20:58:39 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 20:58:39 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 20:58:39 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 20:58:40 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 20:58:40 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 21:07:59 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 21:07:59 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 21:07:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 21:07:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 21:07:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 21:07:59 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 21:07:59 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 21:07:59 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 21:08:00 INFO mapred.JobClient: Running job: job_201305222058_0001
13/05/22 21:08:01 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 21:08:39 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 21:09:09 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 21:09:24 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 21:09:54 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 21:10:13 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 21:10:40 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 21:11:07 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 21:11:22 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 21:11:52 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 21:12:19 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 21:12:36 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 21:13:03 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 21:13:18 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 21:13:49 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 21:14:16 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 21:14:31 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 21:15:01 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 21:15:19 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 21:15:46 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 21:16:13 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 21:16:31 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 21:16:58 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 21:17:13 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 21:17:43 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 21:18:10 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 21:18:25 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 21:18:55 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 21:19:10 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 21:19:37 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 21:20:07 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 21:20:22 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 21:20:52 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 21:21:10 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 21:21:34 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 21:21:55 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 21:22:22 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 21:22:49 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 21:23:04 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 21:23:35 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 21:24:14 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 21:24:17 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 21:24:20 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 21:24:23 INFO mapred.JobClient:  map 40% reduce 4%
13/05/22 21:24:26 INFO mapred.JobClient:  map 40% reduce 6%
13/05/22 21:24:29 INFO mapred.JobClient:  map 40% reduce 7%
13/05/22 21:24:32 INFO mapred.JobClient:  map 40% reduce 10%
13/05/22 21:24:39 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 21:24:42 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 21:25:10 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 21:25:25 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 21:25:55 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 21:26:19 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 21:26:40 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 21:27:07 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 21:27:22 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 21:27:51 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 21:28:12 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 21:28:33 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 21:29:06 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 21:29:21 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 21:29:48 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 21:30:12 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 21:30:33 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 21:31:00 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 21:31:18 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 21:31:45 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 21:32:09 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 21:32:30 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 21:32:57 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 21:33:12 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 21:33:43 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 21:34:07 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 21:34:28 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 21:34:55 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 21:35:13 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 21:35:40 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 21:36:04 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 21:36:25 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 21:36:52 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 21:37:10 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 21:37:37 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 21:38:01 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 21:38:22 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 21:38:49 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 21:39:07 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 21:39:34 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 21:40:07 INFO mapred.JobClient:  map 79% reduce 14%
13/05/22 21:40:10 INFO mapred.JobClient:  map 80% reduce 15%
13/05/22 21:40:13 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 21:40:16 INFO mapred.JobClient:  map 80% reduce 17%
13/05/22 21:40:19 INFO mapred.JobClient:  map 80% reduce 20%
13/05/22 21:40:22 INFO mapred.JobClient:  map 80% reduce 22%
13/05/22 21:40:25 INFO mapred.JobClient:  map 80% reduce 24%
13/05/22 21:40:28 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 21:40:57 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 21:41:39 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 21:42:24 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 21:43:09 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 21:44:04 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 21:44:46 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 21:45:31 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 21:46:16 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 21:47:01 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 21:47:52 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 21:48:37 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 21:49:22 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 21:50:07 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 21:50:55 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 21:51:45 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 21:52:28 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 21:53:15 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 21:54:00 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 21:54:46 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 21:55:46 INFO mapred.JobClient:  map 99% reduce 27%
13/05/22 21:55:49 INFO mapred.JobClient:  map 100% reduce 29%
13/05/22 21:55:52 INFO mapred.JobClient:  map 100% reduce 31%
13/05/22 21:55:55 INFO mapred.JobClient:  map 100% reduce 32%
13/05/22 21:55:58 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 21:56:07 INFO mapred.JobClient:  map 100% reduce 59%
13/05/22 21:56:10 INFO mapred.JobClient:  map 100% reduce 77%
13/05/22 21:56:13 INFO mapred.JobClient:  map 100% reduce 87%
13/05/22 21:56:17 INFO mapred.JobClient:  map 100% reduce 89%
13/05/22 21:56:26 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 21:56:31 INFO mapred.JobClient: Job complete: job_201305222058_0001
13/05/22 21:56:31 INFO mapred.JobClient: Counters: 29
13/05/22 21:56:31 INFO mapred.JobClient:   Job Counters 
13/05/22 21:56:31 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 21:56:31 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28615994
13/05/22 21:56:31 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 21:56:31 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 21:56:31 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 21:56:31 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 21:56:31 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7734796
13/05/22 21:56:31 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 21:56:31 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 21:56:31 INFO mapred.JobClient:   FileSystemCounters
13/05/22 21:56:31 INFO mapred.JobClient:     FILE_BYTES_READ=5338559466
13/05/22 21:56:31 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 21:56:31 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612015885
13/05/22 21:56:31 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 21:56:31 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 21:56:31 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 21:56:31 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 21:56:31 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 21:56:31 INFO mapred.JobClient:     Map input records=120000000
13/05/22 21:56:31 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 21:56:31 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 21:56:31 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 21:56:31 INFO mapred.JobClient:     CPU time spent (ms)=28658920
13/05/22 21:56:31 INFO mapred.JobClient:     Total committed heap usage (bytes)=44031213568
13/05/22 21:56:31 INFO mapred.JobClient:     Combine input records=0
13/05/22 21:56:31 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 21:56:31 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 21:56:31 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 21:56:31 INFO mapred.JobClient:     Combine output records=0
13/05/22 21:56:31 INFO mapred.JobClient:     Physical memory (bytes) snapshot=35989929984
13/05/22 21:56:31 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 21:56:31 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658576437248
13/05/22 21:56:31 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2911904 ms

real	48m32.961s
user	0m6.289s
sys	0m1.070s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     19398  0.0  0.0 106084  1400 ?        Ss   21:56   0:00 bash -c ps aux | grep java
jmg3     19414  0.0  0.0 103232   840 ?        S    21:56   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     22661  0.0  0.0  59072  3528 pts/0    S    21:56   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     22667  0.0  0.0 106084  1396 ?        Ss   21:56   0:00 bash -c ps aux | grep java
jmg3     22683  0.0  0.0 103232   844 ?        R    21:56   0:00 grep java
java: no process killed
java: no process killed
jmg3     19460  0.0  0.0 106084  1400 ?        Ss   21:56   0:00 bash -c ps aux | grep java
jmg3     19476  0.0  0.0 103232   840 ?        S    21:56   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     22749  0.0  0.0  59072  3528 pts/0    S    21:56   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     22755  0.0  0.0 106084  1400 ?        Ss   21:56   0:00 bash -c ps aux | grep java
jmg3     22771  0.0  0.0 103232   844 ?        R    21:56   0:00 grep java
java: no process killed
java: no process killed
jmg3     19522  0.0  0.0 106084  1400 ?        Ss   21:56   0:00 bash -c ps aux | grep java
jmg3     19538  0.0  0.0 103232   844 ?        S    21:56   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     22832  0.0  0.0  59072  3528 pts/0    S    21:56   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     22838  0.0  0.0 106084  1400 ?        Ss   21:56   0:00 bash -c ps aux | grep java
jmg3     22854  0.0  0.0 103232   840 ?        R    21:56   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 21:56:46 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 21:56:46 INFO util.GSet: VM type       = 64-bit
13/05/22 21:56:46 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 21:56:46 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 21:56:46 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 21:56:46 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 21:56:46 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 21:56:46 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 21:56:46 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 21:56:46 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 21:56:46 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 21:56:46 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 21:56:46 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 21:56:46 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 22:06:04 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 22:06:04 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 22:06:04 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 22:06:04 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 22:06:04 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 22:06:04 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 22:06:04 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 22:06:04 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 22:06:05 INFO mapred.JobClient: Running job: job_201305222156_0001
13/05/22 22:06:06 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 22:06:46 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 22:07:16 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 22:07:31 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 22:07:58 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 22:08:16 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 22:08:43 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 22:09:13 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 22:09:31 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 22:09:58 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 22:10:25 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 22:10:43 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 22:11:10 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 22:11:25 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 22:11:55 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 22:12:22 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 22:12:37 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 22:13:07 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 22:13:22 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 22:13:49 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 22:14:16 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 22:14:34 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 22:15:04 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 22:15:19 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 22:15:49 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 22:16:16 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 22:16:34 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 22:17:01 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 22:17:19 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 22:17:43 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 22:18:10 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 22:18:29 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 22:18:56 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 22:19:14 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 22:19:41 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 22:20:02 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 22:20:26 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 22:20:53 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 22:21:11 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 22:21:38 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 22:22:20 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 22:22:23 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 22:22:26 INFO mapred.JobClient:  map 40% reduce 2%
13/05/22 22:22:29 INFO mapred.JobClient:  map 40% reduce 4%
13/05/22 22:22:32 INFO mapred.JobClient:  map 40% reduce 5%
13/05/22 22:22:35 INFO mapred.JobClient:  map 40% reduce 7%
13/05/22 22:22:38 INFO mapred.JobClient:  map 40% reduce 9%
13/05/22 22:22:41 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 22:22:45 INFO mapred.JobClient:  map 41% reduce 11%
13/05/22 22:22:48 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 22:23:13 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 22:23:31 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 22:24:01 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 22:24:25 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 22:24:43 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 22:25:07 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 22:25:28 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 22:25:55 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 22:26:19 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 22:26:43 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 22:27:07 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 22:27:28 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 22:27:54 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 22:28:18 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 22:28:40 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 22:29:04 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 22:29:25 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 22:29:52 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 22:30:16 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 22:30:34 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 22:31:01 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 22:31:19 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 22:31:46 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 22:32:10 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 22:32:31 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 22:32:58 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 22:33:19 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 22:33:46 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 22:34:10 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 22:34:31 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 22:34:55 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 22:35:16 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 22:35:40 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 22:36:07 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 22:36:25 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 22:36:52 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 22:37:10 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 22:37:37 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 22:38:16 INFO mapred.JobClient:  map 80% reduce 14%
13/05/22 22:38:19 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 22:38:22 INFO mapred.JobClient:  map 80% reduce 18%
13/05/22 22:38:25 INFO mapred.JobClient:  map 80% reduce 20%
13/05/22 22:38:28 INFO mapred.JobClient:  map 80% reduce 22%
13/05/22 22:38:31 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 22:38:34 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 22:39:02 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 22:39:47 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 22:40:32 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 22:41:14 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 22:42:08 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 22:42:53 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 22:43:38 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 22:44:23 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 22:45:05 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 22:45:59 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 22:46:44 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 22:47:26 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 22:48:11 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 22:48:59 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 22:49:51 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 22:50:36 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 22:51:21 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 22:52:06 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 22:52:51 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 22:53:51 INFO mapred.JobClient:  map 100% reduce 26%
13/05/22 22:53:54 INFO mapred.JobClient:  map 100% reduce 28%
13/05/22 22:53:57 INFO mapred.JobClient:  map 100% reduce 30%
13/05/22 22:54:00 INFO mapred.JobClient:  map 100% reduce 32%
13/05/22 22:54:03 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 22:54:12 INFO mapred.JobClient:  map 100% reduce 51%
13/05/22 22:54:15 INFO mapred.JobClient:  map 100% reduce 76%
13/05/22 22:54:18 INFO mapred.JobClient:  map 100% reduce 86%
13/05/22 22:54:21 INFO mapred.JobClient:  map 100% reduce 92%
13/05/22 22:54:24 INFO mapred.JobClient:  map 100% reduce 94%
13/05/22 22:54:28 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 22:54:33 INFO mapred.JobClient: Job complete: job_201305222156_0001
13/05/22 22:54:33 INFO mapred.JobClient: Counters: 29
13/05/22 22:54:33 INFO mapred.JobClient:   Job Counters 
13/05/22 22:54:33 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 22:54:33 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28584781
13/05/22 22:54:33 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 22:54:33 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 22:54:33 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 22:54:33 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 22:54:33 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7720637
13/05/22 22:54:33 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 22:54:33 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 22:54:33 INFO mapred.JobClient:   FileSystemCounters
13/05/22 22:54:33 INFO mapred.JobClient:     FILE_BYTES_READ=5338562436
13/05/22 22:54:33 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 22:54:33 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612018855
13/05/22 22:54:33 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 22:54:33 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 22:54:33 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 22:54:33 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 22:54:33 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 22:54:33 INFO mapred.JobClient:     Map input records=120000000
13/05/22 22:54:33 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 22:54:33 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 22:54:33 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 22:54:33 INFO mapred.JobClient:     CPU time spent (ms)=28676080
13/05/22 22:54:33 INFO mapred.JobClient:     Total committed heap usage (bytes)=46804762624
13/05/22 22:54:33 INFO mapred.JobClient:     Combine input records=0
13/05/22 22:54:33 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 22:54:33 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 22:54:33 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 22:54:33 INFO mapred.JobClient:     Combine output records=0
13/05/22 22:54:33 INFO mapred.JobClient:     Physical memory (bytes) snapshot=39236263936
13/05/22 22:54:33 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 22:54:33 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658303791104
13/05/22 22:54:33 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2908889 ms

real	48m29.932s
user	0m6.337s
sys	0m1.006s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     22601  0.0  0.0 106084  1400 ?        Ss   22:54   0:00 bash -c ps aux | grep java
jmg3     22617  0.0  0.0 103232   840 ?        S    22:54   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     24303  0.0  0.0  59072  3532 pts/0    S    22:54   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     24309  0.0  0.0 106084  1400 ?        Ss   22:54   0:00 bash -c ps aux | grep java
jmg3     24325  0.0  0.0 103232   844 ?        R    22:54   0:00 grep java
java: no process killed
java: no process killed
jmg3     22663  0.0  0.0 106084  1396 ?        Ss   22:54   0:00 bash -c ps aux | grep java
jmg3     22679  0.0  0.0 103232   840 ?        S    22:54   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     24391  0.0  0.0  59072  3528 pts/0    S    22:54   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     24397  0.0  0.0 106084  1396 ?        Ss   22:54   0:00 bash -c ps aux | grep java
jmg3     24413  0.0  0.0 103232   848 ?        R    22:54   0:00 grep java
java: no process killed
java: no process killed
jmg3     22725  0.0  0.0 106084  1396 ?        Ss   22:54   0:00 bash -c ps aux | grep java
jmg3     22741  0.0  0.0 103232   840 ?        S    22:54   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     24474  0.0  0.0  59072  3524 pts/0    S    22:54   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     24480  0.0  0.0 106084  1396 ?        Ss   22:54   0:00 bash -c ps aux | grep java
jmg3     24496  0.0  0.0 103232   844 ?        R    22:54   0:00 grep java
Setting path to /tmp/1311669.daman.davinci.rice.edu
12 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 67108864 1 1 1 1 16



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1311669.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${CLASSPATH}:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-016.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>4</value>
  <name>mapred.map.tasks</name><value>12</value>
  <name>opencl.mapper.gpumult</name><value>1</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>1</value>
  <name>opencl.reducer.cpumult</name><value>1</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>12</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>4</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>1200000</value>
  <name>mapred.child.java.opts</name><value>-Xmx16G -Dopencl.mapper.groups.gpu=0 -Dopencl.mapper.groups.cpu=0 -Dopencl.mapper.threadsPerGroup.gpu=0 -Dopencl.mapper.threadsPerGroup.cpu=0 -Dopencl.mapper.buffers.gpu=0 -Dopencl.mapper.buffers.cpu=0 -Dopencl.mapper.bufferSize.gpu=0 -Dopencl.mapper.bufferSize.cpu=0 -Dopencl.reducer.groups.gpu=0 -Dopencl.reducer.groups.cpu=0 -Dopencl.reducer.threadsPerGroup.gpu=0 -Dopencl.reducer.threadsPerGroup.cpu=0 -Dopencl.reducer.buffers.gpu=0 -Dopencl.reducer.buffers.cpu=0 -Dopencl.reducer.bufferSize.gpu=0 -Dopencl.reducer.bufferSize.cpu=0</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
  <name>mapred.user.jobconf.limit</name><value>10485760</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>67108864</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1311669.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-016.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-008
-----------------------------------------------------
gpu-016
-----------------------------------------------------
Completed reconfiguring
Warning: $HADOOP_HOME is deprecated.

13/05/22 22:54:48 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gpu-016.davinci.rice.edu/192.168.110.216
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.0.4-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'jmg3' on Tue May 21 23:11:28 CDT 2013
************************************************************/
13/05/22 22:54:48 INFO util.GSet: VM type       = 64-bit
13/05/22 22:54:48 INFO util.GSet: 2% max memory = 17.77875 MB
13/05/22 22:54:48 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/05/22 22:54:48 INFO util.GSet: recommended=2097152, actual=2097152
13/05/22 22:54:48 INFO namenode.FSNamesystem: fsOwner=jmg3
13/05/22 22:54:48 INFO namenode.FSNamesystem: supergroup=supergroup
13/05/22 22:54:48 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/05/22 22:54:48 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/05/22 22:54:48 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/05/22 22:54:48 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/05/22 22:54:48 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/05/22 22:54:49 INFO common.Storage: Storage directory /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/dfs/name has been successfully formatted.
13/05/22 22:54:49 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at gpu-016.davinci.rice.edu/192.168.110.216
************************************************************/
Completed namenode startup
Warning: $HADOOP_HOME is deprecated.

no jobtracker to stop
gpu-008: no tasktracker to stop
no namenode to stop
gpu-008: no datanode to stop
gpu-016: no secondarynamenode to stop
Completed stop all
Warning: $HADOOP_HOME is deprecated.

starting namenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-016.davinci.rice.edu.out
gpu-008: starting datanode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-008.davinci.rice.edu.out
gpu-016: starting secondarynamenode, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-016.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-016.davinci.rice.edu.out
gpu-008: starting tasktracker, logging to /tmp/1311669.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-008.davinci.rice.edu.out
gpu-008: Max num map slots is 12
Completed start all
Warning: $HADOOP_HOME is deprecated.

Warning: $HADOOP_HOME is deprecated.

13/05/22 23:03:14 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/05/22 23:03:14 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
13/05/22 23:03:14 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 23:03:14 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 23:03:14 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 23:03:14 INFO compress.CodecPool: Got brand-new decompressor
13/05/22 23:03:14 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
13/05/22 23:03:15 INFO input.FileInputFormat: Total input paths to process : 30
13/05/22 23:03:15 INFO mapred.JobClient: Running job: job_201305222254_0001
13/05/22 23:03:16 INFO mapred.JobClient:  map 0% reduce 0%
13/05/22 23:03:54 INFO mapred.JobClient:  map 1% reduce 0%
13/05/22 23:04:25 INFO mapred.JobClient:  map 2% reduce 0%
13/05/22 23:04:40 INFO mapred.JobClient:  map 3% reduce 0%
13/05/22 23:05:10 INFO mapred.JobClient:  map 4% reduce 0%
13/05/22 23:05:25 INFO mapred.JobClient:  map 5% reduce 0%
13/05/22 23:05:55 INFO mapred.JobClient:  map 6% reduce 0%
13/05/22 23:06:26 INFO mapred.JobClient:  map 7% reduce 0%
13/05/22 23:06:41 INFO mapred.JobClient:  map 8% reduce 0%
13/05/22 23:07:08 INFO mapred.JobClient:  map 9% reduce 0%
13/05/22 23:07:35 INFO mapred.JobClient:  map 10% reduce 0%
13/05/22 23:07:53 INFO mapred.JobClient:  map 11% reduce 0%
13/05/22 23:08:20 INFO mapred.JobClient:  map 12% reduce 0%
13/05/22 23:08:35 INFO mapred.JobClient:  map 13% reduce 0%
13/05/22 23:09:05 INFO mapred.JobClient:  map 14% reduce 0%
13/05/22 23:09:32 INFO mapred.JobClient:  map 15% reduce 0%
13/05/22 23:09:47 INFO mapred.JobClient:  map 16% reduce 0%
13/05/22 23:10:17 INFO mapred.JobClient:  map 17% reduce 0%
13/05/22 23:10:31 INFO mapred.JobClient:  map 18% reduce 0%
13/05/22 23:10:58 INFO mapred.JobClient:  map 19% reduce 0%
13/05/22 23:11:28 INFO mapred.JobClient:  map 20% reduce 0%
13/05/22 23:11:43 INFO mapred.JobClient:  map 21% reduce 0%
13/05/22 23:12:13 INFO mapred.JobClient:  map 22% reduce 0%
13/05/22 23:12:28 INFO mapred.JobClient:  map 23% reduce 0%
13/05/22 23:12:58 INFO mapred.JobClient:  map 24% reduce 0%
13/05/22 23:13:25 INFO mapred.JobClient:  map 25% reduce 0%
13/05/22 23:13:44 INFO mapred.JobClient:  map 26% reduce 0%
13/05/22 23:14:11 INFO mapred.JobClient:  map 27% reduce 0%
13/05/22 23:14:26 INFO mapred.JobClient:  map 28% reduce 0%
13/05/22 23:14:56 INFO mapred.JobClient:  map 29% reduce 0%
13/05/22 23:15:23 INFO mapred.JobClient:  map 30% reduce 0%
13/05/22 23:15:38 INFO mapred.JobClient:  map 31% reduce 0%
13/05/22 23:16:08 INFO mapred.JobClient:  map 32% reduce 0%
13/05/22 23:16:23 INFO mapred.JobClient:  map 33% reduce 0%
13/05/22 23:16:53 INFO mapred.JobClient:  map 34% reduce 0%
13/05/22 23:17:08 INFO mapred.JobClient:  map 35% reduce 0%
13/05/22 23:17:35 INFO mapred.JobClient:  map 36% reduce 0%
13/05/22 23:18:05 INFO mapred.JobClient:  map 37% reduce 0%
13/05/22 23:18:20 INFO mapred.JobClient:  map 38% reduce 0%
13/05/22 23:18:47 INFO mapred.JobClient:  map 39% reduce 0%
13/05/22 23:19:29 INFO mapred.JobClient:  map 40% reduce 0%
13/05/22 23:19:32 INFO mapred.JobClient:  map 40% reduce 1%
13/05/22 23:19:35 INFO mapred.JobClient:  map 40% reduce 3%
13/05/22 23:19:38 INFO mapred.JobClient:  map 40% reduce 4%
13/05/22 23:19:41 INFO mapred.JobClient:  map 40% reduce 5%
13/05/22 23:19:44 INFO mapred.JobClient:  map 40% reduce 8%
13/05/22 23:19:47 INFO mapred.JobClient:  map 40% reduce 9%
13/05/22 23:19:50 INFO mapred.JobClient:  map 40% reduce 11%
13/05/22 23:19:53 INFO mapred.JobClient:  map 40% reduce 13%
13/05/22 23:19:57 INFO mapred.JobClient:  map 41% reduce 13%
13/05/22 23:20:21 INFO mapred.JobClient:  map 42% reduce 13%
13/05/22 23:20:39 INFO mapred.JobClient:  map 43% reduce 13%
13/05/22 23:21:09 INFO mapred.JobClient:  map 44% reduce 13%
13/05/22 23:21:33 INFO mapred.JobClient:  map 45% reduce 13%
13/05/22 23:21:54 INFO mapred.JobClient:  map 46% reduce 13%
13/05/22 23:22:21 INFO mapred.JobClient:  map 47% reduce 13%
13/05/22 23:22:39 INFO mapred.JobClient:  map 48% reduce 13%
13/05/22 23:23:06 INFO mapred.JobClient:  map 49% reduce 13%
13/05/22 23:23:34 INFO mapred.JobClient:  map 50% reduce 13%
13/05/22 23:23:52 INFO mapred.JobClient:  map 51% reduce 13%
13/05/22 23:24:19 INFO mapred.JobClient:  map 52% reduce 13%
13/05/22 23:24:37 INFO mapred.JobClient:  map 53% reduce 13%
13/05/22 23:25:04 INFO mapred.JobClient:  map 54% reduce 13%
13/05/22 23:25:28 INFO mapred.JobClient:  map 55% reduce 13%
13/05/22 23:25:49 INFO mapred.JobClient:  map 56% reduce 13%
13/05/22 23:26:13 INFO mapred.JobClient:  map 57% reduce 13%
13/05/22 23:26:34 INFO mapred.JobClient:  map 58% reduce 13%
13/05/22 23:27:01 INFO mapred.JobClient:  map 59% reduce 13%
13/05/22 23:27:28 INFO mapred.JobClient:  map 60% reduce 13%
13/05/22 23:27:46 INFO mapred.JobClient:  map 61% reduce 13%
13/05/22 23:28:13 INFO mapred.JobClient:  map 62% reduce 13%
13/05/22 23:28:31 INFO mapred.JobClient:  map 63% reduce 13%
13/05/22 23:28:58 INFO mapred.JobClient:  map 64% reduce 13%
13/05/22 23:29:25 INFO mapred.JobClient:  map 65% reduce 13%
13/05/22 23:29:43 INFO mapred.JobClient:  map 66% reduce 13%
13/05/22 23:30:10 INFO mapred.JobClient:  map 67% reduce 13%
13/05/22 23:30:28 INFO mapred.JobClient:  map 68% reduce 13%
13/05/22 23:30:54 INFO mapred.JobClient:  map 69% reduce 13%
13/05/22 23:31:21 INFO mapred.JobClient:  map 70% reduce 13%
13/05/22 23:31:39 INFO mapred.JobClient:  map 71% reduce 13%
13/05/22 23:32:06 INFO mapred.JobClient:  map 72% reduce 13%
13/05/22 23:32:27 INFO mapred.JobClient:  map 73% reduce 13%
13/05/22 23:32:51 INFO mapred.JobClient:  map 74% reduce 13%
13/05/22 23:33:18 INFO mapred.JobClient:  map 75% reduce 13%
13/05/22 23:33:37 INFO mapred.JobClient:  map 76% reduce 13%
13/05/22 23:34:04 INFO mapred.JobClient:  map 77% reduce 13%
13/05/22 23:34:22 INFO mapred.JobClient:  map 78% reduce 13%
13/05/22 23:34:49 INFO mapred.JobClient:  map 79% reduce 13%
13/05/22 23:35:25 INFO mapred.JobClient:  map 79% reduce 14%
13/05/22 23:35:28 INFO mapred.JobClient:  map 80% reduce 16%
13/05/22 23:35:31 INFO mapred.JobClient:  map 80% reduce 18%
13/05/22 23:35:34 INFO mapred.JobClient:  map 80% reduce 20%
13/05/22 23:35:37 INFO mapred.JobClient:  map 80% reduce 22%
13/05/22 23:35:40 INFO mapred.JobClient:  map 80% reduce 25%
13/05/22 23:35:43 INFO mapred.JobClient:  map 80% reduce 26%
13/05/22 23:36:11 INFO mapred.JobClient:  map 81% reduce 26%
13/05/22 23:36:56 INFO mapred.JobClient:  map 82% reduce 26%
13/05/22 23:37:41 INFO mapred.JobClient:  map 83% reduce 26%
13/05/22 23:38:26 INFO mapred.JobClient:  map 84% reduce 26%
13/05/22 23:39:11 INFO mapred.JobClient:  map 85% reduce 26%
13/05/22 23:40:02 INFO mapred.JobClient:  map 86% reduce 26%
13/05/22 23:40:47 INFO mapred.JobClient:  map 87% reduce 26%
13/05/22 23:41:32 INFO mapred.JobClient:  map 88% reduce 26%
13/05/22 23:42:17 INFO mapred.JobClient:  map 89% reduce 26%
13/05/22 23:43:08 INFO mapred.JobClient:  map 90% reduce 26%
13/05/22 23:43:53 INFO mapred.JobClient:  map 91% reduce 26%
13/05/22 23:44:38 INFO mapred.JobClient:  map 92% reduce 26%
13/05/22 23:45:23 INFO mapred.JobClient:  map 93% reduce 26%
13/05/22 23:46:08 INFO mapred.JobClient:  map 94% reduce 26%
13/05/22 23:46:53 INFO mapred.JobClient:  map 95% reduce 26%
13/05/22 23:47:47 INFO mapred.JobClient:  map 96% reduce 26%
13/05/22 23:48:32 INFO mapred.JobClient:  map 97% reduce 26%
13/05/22 23:49:14 INFO mapred.JobClient:  map 98% reduce 26%
13/05/22 23:49:59 INFO mapred.JobClient:  map 99% reduce 26%
13/05/22 23:50:44 INFO mapred.JobClient:  map 100% reduce 26%
13/05/22 23:51:05 INFO mapred.JobClient:  map 100% reduce 28%
13/05/22 23:51:08 INFO mapred.JobClient:  map 100% reduce 30%
13/05/22 23:51:11 INFO mapred.JobClient:  map 100% reduce 32%
13/05/22 23:51:14 INFO mapred.JobClient:  map 100% reduce 33%
13/05/22 23:51:23 INFO mapred.JobClient:  map 100% reduce 52%
13/05/22 23:51:26 INFO mapred.JobClient:  map 100% reduce 77%
13/05/22 23:51:29 INFO mapred.JobClient:  map 100% reduce 84%
13/05/22 23:51:32 INFO mapred.JobClient:  map 100% reduce 94%
13/05/22 23:51:38 INFO mapred.JobClient:  map 100% reduce 100%
13/05/22 23:51:43 INFO mapred.JobClient: Job complete: job_201305222254_0001
13/05/22 23:51:43 INFO mapred.JobClient: Counters: 29
13/05/22 23:51:43 INFO mapred.JobClient:   Job Counters 
13/05/22 23:51:43 INFO mapred.JobClient:     Launched reduce tasks=4
13/05/22 23:51:43 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=28612585
13/05/22 23:51:43 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
13/05/22 23:51:43 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
13/05/22 23:51:43 INFO mapred.JobClient:     Launched map tasks=30
13/05/22 23:51:43 INFO mapred.JobClient:     Data-local map tasks=30
13/05/22 23:51:43 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=7730143
13/05/22 23:51:43 INFO mapred.JobClient:   File Output Format Counters 
13/05/22 23:51:43 INFO mapred.JobClient:     Bytes Written=485112
13/05/22 23:51:43 INFO mapred.JobClient:   FileSystemCounters
13/05/22 23:51:43 INFO mapred.JobClient:     FILE_BYTES_READ=5338559403
13/05/22 23:51:43 INFO mapred.JobClient:     HDFS_BYTES_READ=1811534108
13/05/22 23:51:43 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=7612015822
13/05/22 23:51:43 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=485112
13/05/22 23:51:43 INFO mapred.JobClient:   File Input Format Counters 
13/05/22 23:51:43 INFO mapred.JobClient:     Bytes Read=1811530128
13/05/22 23:51:43 INFO mapred.JobClient:   Map-Reduce Framework
13/05/22 23:51:43 INFO mapred.JobClient:     Map output materialized bytes=2155156955
13/05/22 23:51:43 INFO mapred.JobClient:     Map input records=120000000
13/05/22 23:51:43 INFO mapred.JobClient:     Reduce shuffle bytes=2083317125
13/05/22 23:51:43 INFO mapred.JobClient:     Spilled Records=415050090
13/05/22 23:51:43 INFO mapred.JobClient:     Map output bytes=2400000000
13/05/22 23:51:43 INFO mapred.JobClient:     CPU time spent (ms)=28697350
13/05/22 23:51:43 INFO mapred.JobClient:     Total committed heap usage (bytes)=46946058240
13/05/22 23:51:43 INFO mapred.JobClient:     Combine input records=0
13/05/22 23:51:43 INFO mapred.JobClient:     SPLIT_RAW_BYTES=3980
13/05/22 23:51:43 INFO mapred.JobClient:     Reduce input records=120000000
13/05/22 23:51:43 INFO mapred.JobClient:     Reduce input groups=20000
13/05/22 23:51:43 INFO mapred.JobClient:     Combine output records=0
13/05/22 23:51:43 INFO mapred.JobClient:     Physical memory (bytes) snapshot=40870772736
13/05/22 23:51:43 INFO mapred.JobClient:     Reduce output records=20000
13/05/22 23:51:43 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=658643546112
13/05/22 23:51:43 INFO mapred.JobClient:     Map output records=120000000
Execution Time 2908964 ms

real	48m30.021s
user	0m6.289s
sys	0m1.076s
grep: /tmp/1311669.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/userlogs/*: No such file or directory
jmg3     25799  0.0  0.0 106084  1404 ?        Ss   23:51   0:00 bash -c ps aux | grep java
jmg3     25815  0.0  0.0 103232   840 ?        S    23:51   0:00 grep java
jmg3     15905  0.0  0.0 100928   620 pts/0    S+   17:46   0:00 tail -f kmeans.java.compressed
jmg3     25932  0.0  0.0  59072  3532 pts/0    S    23:51   0:00 ssh -o ConnectTimeout=2 gpu-016 ps aux | grep java
jmg3     25938  0.0  0.0 106084  1400 ?        Ss   23:51   0:00 bash -c ps aux | grep java
jmg3     25954  0.0  0.0 103232   840 ?        R    23:51   0:00 grep java
