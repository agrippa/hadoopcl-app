Killing
jmg3     18608  0.0  0.0 106084  1396 ?        Ss   18:46   0:00 bash -c ps aux | grep java
jmg3     18624  0.0  0.0 103232   844 ?        S    18:46   0:00 grep java
jmg3      3017  0.0  0.0  59072  3528 ?        S    18:46   0:00 ssh -o ConnectTimeout=2 gpu-015 ps aux | grep java
jmg3      3023  0.0  0.0 106084  1400 ?        Ss   18:46   0:00 bash -c ps aux | grep java
jmg3      3039  0.0  0.0 103232   840 ?        S    18:46   0:00 grep java
Done
Setting path to /tmp/1221778.daman.davinci.rice.edu
13 5 36 36 256 256 3 3 2097152 2097152 36 36 256 256 3 3 2097152 2097152 268435456 12 1 10 -10



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1221778.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-015.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>5</value>
  <name>mapred.map.tasks</name><value>13</value>
  <name>opencl.mapper.gpumult</name><value>12</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>10</value>
  <name>opencl.reducer.cpumult</name><value>-10</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>13</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>5</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>120000</value>
  <name>mapred.child.java.opts</name><value>-Xmx24G -Dopencl.mapper.groups.gpu=36 -Dopencl.mapper.groups.cpu=36 -Dopencl.mapper.threadsPerGroup.gpu=256 -Dopencl.mapper.threadsPerGroup.cpu=256 -Dopencl.mapper.buffers.gpu=3 -Dopencl.mapper.buffers.cpu=3 -Dopencl.mapper.bufferSize.gpu=2097152 -Dopencl.mapper.bufferSize.cpu=2097152 -Dopencl.reducer.groups.gpu=36 -Dopencl.reducer.groups.cpu=36 -Dopencl.reducer.threadsPerGroup.gpu=256 -Dopencl.reducer.threadsPerGroup.cpu=256 -Dopencl.reducer.buffers.gpu=3 -Dopencl.reducer.buffers.cpu=3 -Dopencl.reducer.bufferSize.gpu=2097152 -Dopencl.reducer.bufferSize.cpu=2097152</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>268435456</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1221778.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-015.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-013
-----------------------------------------------------
gpu-015
-----------------------------------------------------
Completed reconfiguring
Completed namenode startup
no jobtracker to stop
gpu-013: no tasktracker to stop
no namenode to stop
gpu-013: no datanode to stop
gpu-015: no secondarynamenode to stop
Completed stop all
starting namenode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-015.davinci.rice.edu.out
gpu-013: starting datanode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-013.davinci.rice.edu.out
gpu-015: starting secondarynamenode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-015.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-015.davinci.rice.edu.out
gpu-013: starting tasktracker, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-013.davinci.rice.edu.out
gpu-013: Max num map slots is 13
Completed start all
Putting inputs
Running Application
attempt_201303301847_0001_r_000004_0: #
attempt_201303301847_0001_r_000004_0: # A fatal error has been detected by the Java Runtime Environment:
attempt_201303301847_0001_r_000004_0: #
attempt_201303301847_0001_r_000004_0: #  SIGSEGV (0xb) at pc=0x000000343ec7a5ac, pid=2168, tid=140051726276352
attempt_201303301847_0001_r_000004_0: #
attempt_201303301847_0001_r_000004_0: # JRE version: 6.0_25-b06
attempt_201303301847_0001_r_000004_0: # Java VM: Java HotSpot(TM) 64-Bit Server VM (20.0-b11 mixed mode linux-amd64 compressed oops)
attempt_201303301847_0001_r_000004_0: # Problematic frame:
attempt_201303301847_0001_r_000004_0: # C  [libc.so.6+0x7a5ac]  char+0x1c
attempt_201303301847_0001_r_000004_0: #
attempt_201303301847_0001_r_000004_0: # An error report file with more information is saved as:
attempt_201303301847_0001_r_000004_0: # /tmp/1221660.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/taskTracker/jmg3/jobcache/job_201303301847_0001/attempt_201303301847_0001_r_000004_0/work/hs_err_pid2168.log
attempt_201303301847_0001_r_000004_0: #
attempt_201303301847_0001_r_000004_0: # If you would like to submit a bug report, please visit:
attempt_201303301847_0001_r_000004_0: #   http://java.sun.com/webapps/bugreport/crash.jsp
attempt_201303301847_0001_r_000004_0: # The crash happened outside the Java Virtual Machine in native code.
attempt_201303301847_0001_r_000004_0: # See problematic frame for where to report the bug.
attempt_201303301847_0001_r_000004_0: #
Done, Killing
jmg3     20724  0.0  0.0 106084  1396 ?        Ss   18:52   0:00 bash -c ps aux | grep java
jmg3     20740  0.0  0.0 103232   840 ?        S    18:52   0:00 grep java
jmg3      4208  0.0  0.0  58312  3532 ?        S    18:52   0:00 ssh -o ConnectTimeout=2 gpu-015 ps aux | grep java
jmg3      4214  0.0  0.0 106084  1400 ?        Ss   18:52   0:00 bash -c ps aux | grep java
jmg3      4230  0.0  0.0 103232   840 ?        S    18:52   0:00 grep java
Killing
jmg3     20786  0.0  0.0 106084  1400 ?        Ss   18:52   0:00 bash -c ps aux | grep java
jmg3     20802  0.0  0.0 103232   844 ?        S    18:52   0:00 grep java
jmg3      4289  0.0  0.0  59072  3528 ?        S    18:52   0:00 ssh -o ConnectTimeout=2 gpu-015 ps aux | grep java
jmg3      4295  0.0  0.0 106084  1396 ?        Ss   18:52   0:00 bash -c ps aux | grep java
jmg3      4311  0.0  0.0 103232   840 ?        S    18:52   0:00 grep java
Done
Setting path to /tmp/1221778.daman.davinci.rice.edu
13 5 36 36 256 256 3 3 2097152 2097152 36 36 256 256 3 3 2097152 2097152 268435456 12 1 10 -10



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1221778.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-015.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>5</value>
  <name>mapred.map.tasks</name><value>13</value>
  <name>opencl.mapper.gpumult</name><value>12</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>10</value>
  <name>opencl.reducer.cpumult</name><value>-10</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>13</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>5</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>120000</value>
  <name>mapred.child.java.opts</name><value>-Xmx24G -Dopencl.mapper.groups.gpu=36 -Dopencl.mapper.groups.cpu=36 -Dopencl.mapper.threadsPerGroup.gpu=256 -Dopencl.mapper.threadsPerGroup.cpu=256 -Dopencl.mapper.buffers.gpu=3 -Dopencl.mapper.buffers.cpu=3 -Dopencl.mapper.bufferSize.gpu=2097152 -Dopencl.mapper.bufferSize.cpu=2097152 -Dopencl.reducer.groups.gpu=36 -Dopencl.reducer.groups.cpu=36 -Dopencl.reducer.threadsPerGroup.gpu=256 -Dopencl.reducer.threadsPerGroup.cpu=256 -Dopencl.reducer.buffers.gpu=3 -Dopencl.reducer.buffers.cpu=3 -Dopencl.reducer.bufferSize.gpu=2097152 -Dopencl.reducer.bufferSize.cpu=2097152</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>268435456</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1221778.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-015.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-013
-----------------------------------------------------
gpu-015
-----------------------------------------------------
Completed reconfiguring
Completed namenode startup
no jobtracker to stop
gpu-013: no tasktracker to stop
no namenode to stop
gpu-013: no datanode to stop
gpu-015: no secondarynamenode to stop
Completed stop all
starting namenode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-015.davinci.rice.edu.out
gpu-013: starting datanode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-013.davinci.rice.edu.out
gpu-015: starting secondarynamenode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-015.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-015.davinci.rice.edu.out
gpu-013: starting tasktracker, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-013.davinci.rice.edu.out
gpu-013: Max num map slots is 13
Completed start all
Putting inputs
Running Application
attempt_201303301852_0001_r_000004_0: #
attempt_201303301852_0001_r_000004_0: # A fatal error has been detected by the Java Runtime Environment:
attempt_201303301852_0001_r_000004_0: #
attempt_201303301852_0001_r_000004_0: #  SIGSEGV (0xb) at pc=0x000000343ec7a5ac, pid=4048, tid=140593447077632
attempt_201303301852_0001_r_000004_0: #
attempt_201303301852_0001_r_000004_0: # JRE version: 6.0_25-b06
attempt_201303301852_0001_r_000004_0: # Java VM: Java HotSpot(TM) 64-Bit Server VM (20.0-b11 mixed mode linux-amd64 compressed oops)
attempt_201303301852_0001_r_000004_0: # Problematic frame:
attempt_201303301852_0001_r_000004_0: # C  [libc.so.6+0x7a5ac]  char+0x1c
attempt_201303301852_0001_r_000004_0: #
attempt_201303301852_0001_r_000004_0: # An error report file with more information is saved as:
attempt_201303301852_0001_r_000004_0: # /tmp/1221660.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/taskTracker/jmg3/jobcache/job_201303301852_0001/attempt_201303301852_0001_r_000004_0/work/hs_err_pid4048.log
attempt_201303301852_0001_r_000004_0: #
attempt_201303301852_0001_r_000004_0: # If you would like to submit a bug report, please visit:
attempt_201303301852_0001_r_000004_0: #   http://java.sun.com/webapps/bugreport/crash.jsp
attempt_201303301852_0001_r_000004_0: # The crash happened outside the Java Virtual Machine in native code.
attempt_201303301852_0001_r_000004_0: # See problematic frame for where to report the bug.
attempt_201303301852_0001_r_000004_0: #
Done, Killing
jmg3     22906  0.0  0.0 106084  1400 ?        Ss   18:58   0:00 bash -c ps aux | grep java
jmg3     22922  0.0  0.0 103232   844 ?        S    18:58   0:00 grep java
jmg3      5398  0.0  0.0  59072  3528 ?        S    18:58   0:00 ssh -o ConnectTimeout=2 gpu-015 ps aux | grep java
jmg3      5404  0.0  0.0 106084  1400 ?        Ss   18:58   0:00 bash -c ps aux | grep java
jmg3      5420  0.0  0.0 103232   844 ?        S    18:58   0:00 grep java
Killing
jmg3     22968  0.0  0.0 106084  1400 ?        Ss   18:58   0:00 bash -c ps aux | grep java
jmg3     22984  0.0  0.0 103232   840 ?        S    18:58   0:00 grep java
jmg3      5479  0.0  0.0  59072  3528 ?        S    18:58   0:00 ssh -o ConnectTimeout=2 gpu-015 ps aux | grep java
jmg3      5485  0.0  0.0 106084  1396 ?        Ss   18:58   0:00 bash -c ps aux | grep java
jmg3      5502  0.0  0.0 103232   840 ?        S    18:58   0:00 grep java
Done
Setting path to /tmp/1221778.daman.davinci.rice.edu
13 5 36 36 256 256 3 3 2097152 2097152 36 36 256 256 3 3 2097152 2097152 268435456 12 1 10 -10



Here are the results:
export JAVA_HOME=/opt/apps/jdk/1.6
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_LOG_DIR=/tmp/1221778.daman.davinci.rice.edu/logs
export HADOOP_CLASSPATH=/home/jmg3/hadoop-gpl-compression-read-only/build/hadoop-gpl-compression-0.2.0-dev.jar:${HADOOP_CLASSPATH}
export JAVA_LIBRARY_PATH=/home/jmg3/lzo-install/lib:${JAVA_LIBRARY_PATH}
-----------------------------------------------------
  <name>mapred.job.tracker</name>
  <value>gpu-015.davinci.rice.edu:54311</value>
  <name>mapred.reduce.parallel.copies</name><value>5</value>
  <name>task.tracker.http.threads</name><value>40</value>
  <name>mapred.reduce.tasks</name><value>5</value>
  <name>mapred.map.tasks</name><value>13</value>
  <name>opencl.mapper.gpumult</name><value>12</value>
  <name>opencl.mapper.cpumult</name><value>1</value>
  <name>opencl.reducer.gpumult</name><value>10</value>
  <name>opencl.reducer.cpumult</name><value>-10</value>
  <name>mapred.tasktracker.map.tasks.maximum</name><value>13</value>
  <name>mapred.tasktracker.reduce.tasks.maximum</name><value>5</value>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>true</value>
  <name>mapred.task.timeout</name><value>120000</value>
  <name>mapred.child.java.opts</name><value>-Xmx24G -Dopencl.mapper.groups.gpu=36 -Dopencl.mapper.groups.cpu=36 -Dopencl.mapper.threadsPerGroup.gpu=256 -Dopencl.mapper.threadsPerGroup.cpu=256 -Dopencl.mapper.buffers.gpu=3 -Dopencl.mapper.buffers.cpu=3 -Dopencl.mapper.bufferSize.gpu=2097152 -Dopencl.mapper.bufferSize.cpu=2097152 -Dopencl.reducer.groups.gpu=36 -Dopencl.reducer.groups.cpu=36 -Dopencl.reducer.threadsPerGroup.gpu=256 -Dopencl.reducer.threadsPerGroup.cpu=256 -Dopencl.reducer.buffers.gpu=3 -Dopencl.reducer.buffers.cpu=3 -Dopencl.reducer.bufferSize.gpu=2097152 -Dopencl.reducer.bufferSize.cpu=2097152</value>
  <name>mapred.map.tasks.speculative.execution</name><value>false</value>
  <name>mapred.reduce.tasks.speculative.execution</name><value>false</value>
-----------------------------------------------------
  <name>dfs.safemode.threshold.pct</name>
  <value>0</value>
  <name>dfs.replication</name><value>3</value>
  <name>dfs.block.size</name><value>268435456</value>
  <name>dfs.datanode.handler.count</name><value>3</value>
  <name>dfs.namenode.handler.count</name><value>10</value>
  <name>dfs.datanode.max.xcievers</name><value>256</value>
-----------------------------------------------------
  <name>hadoop.tmp.dir</name>
  <value>/tmp/1221778.daman.davinci.rice.edu/hadoop-${user.name}</value>
  <name>fs.default.name</name>
  <value>hdfs://gpu-015.davinci.rice.edu:54310</value>
<name>io.compression.codecs</name>
<value>
</value>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
-----------------------------------------------------
gpu-013
-----------------------------------------------------
gpu-015
-----------------------------------------------------
Completed reconfiguring
Completed namenode startup
no jobtracker to stop
gpu-013: no tasktracker to stop
no namenode to stop
gpu-013: no datanode to stop
gpu-015: no secondarynamenode to stop
Completed stop all
starting namenode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-namenode-gpu-015.davinci.rice.edu.out
gpu-013: starting datanode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-datanode-gpu-013.davinci.rice.edu.out
gpu-015: starting secondarynamenode, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-secondarynamenode-gpu-015.davinci.rice.edu.out
starting jobtracker, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-jobtracker-gpu-015.davinci.rice.edu.out
gpu-013: starting tasktracker, logging to /tmp/1221778.daman.davinci.rice.edu/logs/hadoop-jmg3-tasktracker-gpu-013.davinci.rice.edu.out
gpu-013: Max num map slots is 13
Completed start all
Putting inputs
Running Application
attempt_201303301859_0001_r_000004_0: #
attempt_201303301859_0001_r_000004_0: # A fatal error has been detected by the Java Runtime Environment:
attempt_201303301859_0001_r_000004_0: #
attempt_201303301859_0001_r_000004_0: #  SIGSEGV (0xb) at pc=0x000000343ec7a5ac, pid=5814, tid=139677346477824
attempt_201303301859_0001_r_000004_0: #
attempt_201303301859_0001_r_000004_0: # JRE version: 6.0_25-b06
attempt_201303301859_0001_r_000004_0: # Java VM: Java HotSpot(TM) 64-Bit Server VM (20.0-b11 mixed mode linux-amd64 compressed oops)
attempt_201303301859_0001_r_000004_0: # Problematic frame:
attempt_201303301859_0001_r_000004_0: # C  [libc.so.6+0x7a5ac]  char+0x1c
attempt_201303301859_0001_r_000004_0: #
attempt_201303301859_0001_r_000004_0: # An error report file with more information is saved as:
attempt_201303301859_0001_r_000004_0: # /tmp/1221660.daman.davinci.rice.edu/hadoop-jmg3/mapred/local/taskTracker/jmg3/jobcache/job_201303301859_0001/attempt_201303301859_0001_r_000004_0/work/hs_err_pid5814.log
attempt_201303301859_0001_r_000004_0: #
attempt_201303301859_0001_r_000004_0: # If you would like to submit a bug report, please visit:
attempt_201303301859_0001_r_000004_0: #   http://java.sun.com/webapps/bugreport/crash.jsp
attempt_201303301859_0001_r_000004_0: # The crash happened outside the Java Virtual Machine in native code.
attempt_201303301859_0001_r_000004_0: # See problematic frame for where to report the bug.
attempt_201303301859_0001_r_000004_0: #
Done, Killing
jmg3     24957  0.0  0.0 106084  1400 ?        Ss   19:04   0:00 bash -c ps aux | grep java
jmg3     24973  0.0  0.0 103232   844 ?        S    19:04   0:00 grep java
jmg3      6594  0.0  0.0  59072  3528 ?        S    19:04   0:00 ssh -o ConnectTimeout=2 gpu-015 ps aux | grep java
jmg3      6600  0.0  0.0 106084  1396 ?        Ss   19:04   0:00 bash -c ps aux | grep java
jmg3      6616  0.0  0.0 103232   840 ?        S    19:04   0:00 grep java
